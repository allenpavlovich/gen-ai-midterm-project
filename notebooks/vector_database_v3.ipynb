{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Vector Database with ChromaDB (v3)\n",
    "\n",
    "This notebook creates a vector database using ChromaDB for the header-based chunks and embeddings generated by `generate_embeddings_v3.ipynb`. It loads the embeddings from the specified directory and creates a ChromaDB collection for efficient semantic search and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm # For progress bars in Jupyter\n",
    "import logging \n",
    "import time # For timing the main execution\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ChromaDB\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For query embedding and testing\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch # For checking CUDA availability for SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "# Directory with the latest stored embeddings\n",
    "EMBEDDINGS_BASE_DIR = \"../data/embeddings\"\n",
    "EMBEDDINGS_SUB_DIR = \"header_chunks_all_MiniLM_L6_v2_20250512_231425\"  # Update this to the directory name you want to use\n",
    "EMBEDDINGS_DIR = os.path.join(EMBEDDINGS_BASE_DIR, EMBEDDINGS_SUB_DIR)\n",
    "\n",
    "# File containing chunks with their pre-computed embeddings and metadata\n",
    "CHUNKS_WITH_EMBEDDINGS_FILE = os.path.join(EMBEDDINGS_DIR, \"chunks_with_embeddings.json\") \n",
    "\n",
    "# Directory to store ChromaDB persistent files\n",
    "CHROMA_DB_DIR = \"../data/chroma_db/header_chunks\"  \n",
    "\n",
    "# Output directory for log files\n",
    "LOGS_DIR = \"../logs\" \n",
    "\n",
    "# Name for the ChromaDB collection\n",
    "COLLECTION_NAME = \"uchicago_ms_applied_ds_header_chunks\"\n",
    "\n",
    "# Sentence Transformer model name (must be the same as used for generating document embeddings)\n",
    "QUERY_EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\" # all-MiniLM-L6-v2\n",
    "\n",
    "# Batch size for adding documents to ChromaDB\n",
    "CHROMA_ADD_BATCH_SIZE = 100 # Adjust based on your system's memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories if they don't exist\n",
    "Path(CHROMA_DB_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(LOGS_DIR).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "log_file = Path(LOGS_DIR) / f\"vector_database_v3_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(module)s - %(funcName)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file, encoding='utf-8'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file contains the fixed version of the vector_database_v3.py script.\n",
    "The key fix is in the load_data_for_chroma function to properly handle None values in metadata.\n",
    "\"\"\"\n",
    "\n",
    "def load_data_for_chroma(chunks_with_embeddings_filepath_str):\n",
    "    \"\"\"\n",
    "    Load chunks, their pre-computed embeddings, and metadata from the JSON file.\n",
    "    Prepares data in the format required by ChromaDB.\n",
    "    \n",
    "    FIXED: This version properly handles None values in metadata\n",
    "    \"\"\"\n",
    "    chunks_file = Path(chunks_with_embeddings_filepath_str)\n",
    "    if not chunks_file.exists():\n",
    "        logger.error(f\"Data file not found: {chunks_file}. Please run the embedding generation script first.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    try:\n",
    "        with open(chunks_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            loaded_data = json.load(f)\n",
    "        \n",
    "        logger.info(f\"Loaded {len(loaded_data)} items from {chunks_file}\")\n",
    "        \n",
    "        ids_list = []\n",
    "        embeddings_list = []\n",
    "        documents_list = []\n",
    "        metadatas_list = []\n",
    "        \n",
    "        for i, item in enumerate(tqdm(loaded_data, desc=\"Preparing data for ChromaDB\")):\n",
    "            # Using page_content as the primary field, with fallback to content or text\n",
    "            doc_content = item.get('page_content', item.get('content', item.get('text', '')))\n",
    "            embedding_vector = item.get('embedding')\n",
    "            \n",
    "            # Initialize metadata_dict - start with an empty dict\n",
    "            metadata_dict = {}\n",
    "            \n",
    "            # If metadata exists, copy it first\n",
    "            if 'metadata' in item and isinstance(item['metadata'], dict):\n",
    "                for k, v in item['metadata'].items():\n",
    "                    if v is None:\n",
    "                        # Convert None to string \"None\"\n",
    "                        metadata_dict[k] = \"None\"\n",
    "                    elif isinstance(v, (str, int, float, bool)):\n",
    "                        metadata_dict[k] = v\n",
    "                    else:\n",
    "                        # Convert any other types to string\n",
    "                        metadata_dict[k] = str(v)\n",
    "            \n",
    "            # Add other fields from the item to metadata, except embedding and content\n",
    "            for key, value in item.items():\n",
    "                if key not in ['embedding', 'page_content', 'content', 'text', 'metadata']:\n",
    "                    if value is None:\n",
    "                        metadata_dict[key] = \"None\"  # Convert None to string\n",
    "                    elif isinstance(value, (str, int, float, bool)):\n",
    "                        metadata_dict[key] = value\n",
    "                    else:\n",
    "                        metadata_dict[key] = str(value)  # Convert other types to string\n",
    "            \n",
    "            if not doc_content or embedding_vector is None:\n",
    "                logger.warning(f\"Skipping item at index {i} due to missing content or embedding.\")\n",
    "                continue\n",
    "            \n",
    "            # Add chunk_id as the document ID if available\n",
    "            doc_id = item.get('chunk_id', item.get('id', f\"doc_{i}\"))\n",
    "            \n",
    "            ids_list.append(doc_id)\n",
    "            embeddings_list.append(embedding_vector)\n",
    "            documents_list.append(doc_content)\n",
    "            metadatas_list.append(metadata_dict)\n",
    "        \n",
    "        if not ids_list:\n",
    "            logger.error(\"No valid data to load for ChromaDB.\")\n",
    "            return None, None, None, None\n",
    "\n",
    "        logger.info(f\"Prepared {len(ids_list)} items for ChromaDB.\")\n",
    "        logger.info(f\"Sample ID: {ids_list[0]}\")\n",
    "        logger.info(f\"Sample Document (start): {documents_list[0][:100]}...\")\n",
    "        logger.info(f\"Sample Metadata: {metadatas_list[0]}\")\n",
    "        \n",
    "        return ids_list, embeddings_list, documents_list, metadatas_list\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"Error parsing JSON file {chunks_file}: {e}\")\n",
    "        return None, None, None, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error loading data for ChromaDB: {e}\", exc_info=True)\n",
    "        return None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChromaDB client and collection initialization\n",
    "def initialize_chroma_client_and_collection(db_path_str, collection_name_str):\n",
    "    \"\"\"\n",
    "    Initialize ChromaDB client and create/get a collection.\n",
    "    \n",
    "    Args:\n",
    "        db_path_str (str): Path to the ChromaDB persistent directory\n",
    "        collection_name_str (str): Name of the collection to create or get\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (client, collection) instances or (None, None) if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Initializing ChromaDB client with persistence path: {db_path_str}\")\n",
    "        client = chromadb.PersistentClient(path=db_path_str)\n",
    "        \n",
    "        # Create a new collection or get existing one\n",
    "        try:\n",
    "            # Try to get existing collection\n",
    "            collection = client.get_collection(name=collection_name_str)\n",
    "            logger.info(f\"Loaded existing collection '{collection_name_str}' with {collection.count()} documents\")\n",
    "        except Exception:\n",
    "            # Create new collection if it doesn't exist\n",
    "            logger.info(f\"Creating new collection '{collection_name_str}'\")\n",
    "            collection = client.create_collection(\n",
    "                name=collection_name_str,\n",
    "                metadata={\"description\": \"UChicago MS in Applied Data Science documents\"}\n",
    "            )\n",
    "            logger.info(f\"Created new collection '{collection_name_str}'\")\n",
    "        \n",
    "        return client, collection\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error initializing ChromaDB client or collection: {e}\", exc_info=True)\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data to ChromaDB collection\n",
    "def add_data_to_chroma_collection(collection_instance, ids_list, embeddings_list, documents_list, metadatas_list, batch_size=CHROMA_ADD_BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Add data to the ChromaDB collection in batches.\n",
    "    \n",
    "    Args:\n",
    "        collection_instance: ChromaDB collection instance\n",
    "        ids_list: List of document IDs\n",
    "        embeddings_list: List of embedding vectors\n",
    "        documents_list: List of document texts\n",
    "        metadatas_list: List of document metadata dictionaries\n",
    "        batch_size: Number of documents to add in each batch\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        n_items = len(ids_list)\n",
    "        logger.info(f\"Adding {n_items} documents to collection in batches of {batch_size}\")\n",
    "        \n",
    "        for i in tqdm(range(0, n_items, batch_size), desc=\"Adding batches to ChromaDB\"):\n",
    "            batch_end_idx = min(i + batch_size, n_items)\n",
    "            \n",
    "            current_batch_ids = ids_list[i:batch_end_idx]\n",
    "            current_batch_embeddings = embeddings_list[i:batch_end_idx]\n",
    "            current_batch_documents = documents_list[i:batch_end_idx]\n",
    "            current_batch_metadatas = metadatas_list[i:batch_end_idx]\n",
    "            \n",
    "            collection_instance.add(\n",
    "                ids=current_batch_ids,\n",
    "                embeddings=current_batch_embeddings,\n",
    "                documents=current_batch_documents,\n",
    "                metadatas=current_batch_metadatas\n",
    "            )\n",
    "            \n",
    "        logger.info(f\"Successfully added all {n_items} documents to ChromaDB collection\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error adding data to ChromaDB: {e}\", exc_info=True)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize query embedding model\n",
    "def initialize_query_embedding_model(model_name=QUERY_EMBEDDING_MODEL_NAME):\n",
    "    \"\"\"\n",
    "    Initialize the Sentence Transformer model for encoding query texts.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Name of the pre-trained model to use\n",
    "        \n",
    "    Returns:\n",
    "        SentenceTransformer: Initialized model or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Loading query embedding model: {model_name}\")\n",
    "        model = SentenceTransformer(model_name)\n",
    "        \n",
    "        # Check if we can use GPU\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        model.to(device)\n",
    "        logger.info(f\"Query embedding model loaded and using device: {device}\")\n",
    "        \n",
    "        return model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading query embedding model '{model_name}': {e}\", exc_info=True)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query function for the ChromaDB collection\n",
    "def query_chroma_collection(collection_instance, query_text, embedding_model, top_n_results=5, metadata_filter_dict=None):\n",
    "    \"\"\"\n",
    "    Query the ChromaDB collection using the given query text.\n",
    "    \n",
    "    Args:\n",
    "        collection_instance: ChromaDB collection instance\n",
    "        query_text (str): The query text to search for\n",
    "        embedding_model: SentenceTransformer model for encoding the query\n",
    "        top_n_results (int): Number of results to return\n",
    "        metadata_filter_dict (dict, optional): Dictionary for filtering results by metadata fields\n",
    "        \n",
    "    Returns:\n",
    "        dict: Query results from ChromaDB\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate embedding for the query text\n",
    "        query_embedding = embedding_model.encode(query_text)\n",
    "        \n",
    "        # Query the collection\n",
    "        results = collection_instance.query(\n",
    "            query_embeddings=[query_embedding],\n",
    "            n_results=top_n_results,\n",
    "            where=metadata_filter_dict,  # Optional metadata filter\n",
    "            include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error querying ChromaDB: {e}\", exc_info=True)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display query results\n",
    "def display_query_search_results(results, query_text):\n",
    "    \"\"\"\n",
    "    Display the results of a ChromaDB query in a readable format.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): Results from a ChromaDB query\n",
    "        query_text (str): The original query text\n",
    "    \"\"\"\n",
    "    if not results or not results.get('documents'):\n",
    "        logger.info(f\"No results found for query: '{query_text}'\")\n",
    "        return\n",
    "    \n",
    "    docs = results.get('documents', [[]])[0]\n",
    "    metadatas = results.get('metadatas', [[]])[0]\n",
    "    distances = results.get('distances', [[]])[0]\n",
    "    \n",
    "    logger.info(f\"\\n--- Results for query: '{query_text}' ---\")\n",
    "    \n",
    "    for i, (doc, meta, dist) in enumerate(zip(docs, metadatas, distances)):\n",
    "        logger.info(f\"\\nResult #{i+1} (Distance: {dist:.4f}):\")\n",
    "        \n",
    "        # Display metadata\n",
    "        if meta:\n",
    "            title = meta.get('document_title', meta.get('title', 'Unknown'))\n",
    "            section = meta.get('section', '')\n",
    "            subsection = meta.get('subsection', '')\n",
    "            logger.info(f\"Document: {title}\")\n",
    "            if section:\n",
    "                logger.info(f\"Section: {section}\")\n",
    "            if subsection:\n",
    "                logger.info(f\"Subsection: {subsection}\")\n",
    "        \n",
    "        # Display document snippet\n",
    "        doc_snippet = doc[:300] + \"...\" if len(doc) > 300 else doc\n",
    "        logger.info(f\"Content: {doc_snippet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build a context for retrieval-augmented generation\n",
    "def build_retrieval_context(query_text, top_k_docs, collection_inst, query_embed_model_inst):\n",
    "    \"\"\"\n",
    "    Build a retrieval context by querying the ChromaDB collection.\n",
    "    This context can be used for RAG applications.\n",
    "    \n",
    "    Args:\n",
    "        query_text (str): The query text\n",
    "        top_k_docs (int): Number of documents to retrieve\n",
    "        collection_inst: ChromaDB collection instance\n",
    "        query_embed_model_inst: SentenceTransformer model instance\n",
    "        \n",
    "    Returns:\n",
    "        list: List of retrieved context strings\n",
    "    \"\"\"\n",
    "    results = query_chroma_collection(\n",
    "        collection_inst, \n",
    "        query_text, \n",
    "        query_embed_model_inst, \n",
    "        top_n_results=top_k_docs\n",
    "    )\n",
    "    \n",
    "    if not results or not results.get('documents'):\n",
    "        logger.warning(f\"No documents retrieved for query: '{query_text}'\")\n",
    "        return []\n",
    "    \n",
    "    # Extract documents and their metadata\n",
    "    retrieved_contexts = []\n",
    "    docs = results.get('documents', [[]])[0]\n",
    "    metadatas = results.get('metadatas', [[]])[0]\n",
    "    \n",
    "    for i, (doc, meta) in enumerate(zip(docs, metadatas)):\n",
    "        # Create a formatted context string with metadata and content\n",
    "        title = meta.get('document_title', meta.get('title', 'Unknown'))\n",
    "        section = meta.get('section', '')\n",
    "        subsection = meta.get('subsection', '')\n",
    "        \n",
    "        context_header = f\"Source {i+1}: {title}\"\n",
    "        if section:\n",
    "            context_header += f\" | Section: {section}\"\n",
    "        if subsection:\n",
    "            context_header += f\" | Subsection: {subsection}\"\n",
    "            \n",
    "        context_str = f\"{context_header}\\n\\n{doc}\\n\"\n",
    "        retrieved_contexts.append(context_str)\n",
    "    \n",
    "    return retrieved_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 23:21:58,385 - INFO - 914924386 - <module> - Starting vector database creation process\n",
      "2025-05-12 23:21:58,436 - INFO - 2989996848 - load_data_for_chroma - Loaded 203 items from ..\\data\\embeddings\\header_chunks_all_MiniLM_L6_v2_20250512_231425\\chunks_with_embeddings.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a137ca3314e44e91aa2715be0a8eda68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing data for ChromaDB:   0%|          | 0/203 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 23:21:58,448 - INFO - 2989996848 - load_data_for_chroma - Prepared 203 items for ChromaDB.\n",
      "2025-05-12 23:21:58,449 - INFO - 2989996848 - load_data_for_chroma - Sample ID: chunk_0\n",
      "2025-05-12 23:21:58,450 - INFO - 2989996848 - load_data_for_chroma - Sample Document (start): ## Your Career Success\n",
      "\n",
      "Take the next step to advance your career with UChicago’s MS in Applied Data...\n",
      "2025-05-12 23:21:58,452 - INFO - 2989996848 - load_data_for_chroma - Sample Metadata: {'title': 'In-Person Program – DSI', 'original_url': 'https://datascience.uchicago.edu/education/masters-programs/in-person-program', 'category': 'education', 'date': '2025-05-04', 'source_file': 'C:\\\\Users\\\\alen.pavlovic\\\\Documents\\\\GitLab\\\\gen-ai-midterm-project\\\\data\\\\markdown_clean_final\\\\education_masters-programs_in-person-program.md', 'filename': 'education_masters-programs_in-person-program.md', 'section_level': 'main', 'section': 'Your Career Success', 'subsection': 'None', 'header_level': 2, 'header_text': 'Your Career Success', 'chunk_id': 'education_masters-programs_in-person-program_0', 'document_title': 'In-Person Program – DSI', 'id': 'chunk_0'}\n",
      "2025-05-12 23:21:58,453 - INFO - 2647484719 - initialize_chroma_client_and_collection - Initializing ChromaDB client with persistence path: ../data/chroma_db/header_chunks\n",
      "2025-05-12 23:21:58,470 - INFO - posthog - __init__ - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-05-12 23:21:58,623 - INFO - 2647484719 - initialize_chroma_client_and_collection - Creating new collection 'uchicago_ms_applied_ds_header_chunks'\n",
      "2025-05-12 23:21:58,690 - INFO - 2647484719 - initialize_chroma_client_and_collection - Created new collection 'uchicago_ms_applied_ds_header_chunks'\n",
      "2025-05-12 23:21:58,692 - INFO - 1570821046 - add_data_to_chroma_collection - Adding 203 documents to collection in batches of 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb2c93423e14d5590a12fa55975fa6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding batches to ChromaDB:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 23:21:59,079 - INFO - 1570821046 - add_data_to_chroma_collection - Successfully added all 203 documents to ChromaDB collection\n",
      "2025-05-12 23:21:59,081 - INFO - 914924386 - <module> - ChromaDB collection 'uchicago_ms_applied_ds_header_chunks' created successfully with 203 documents\n",
      "2025-05-12 23:21:59,084 - INFO - 2479983000 - initialize_query_embedding_model - Loading query embedding model: all-MiniLM-L6-v2\n",
      "2025-05-12 23:21:59,086 - INFO - SentenceTransformer - __init__ - Use pytorch device_name: cpu\n",
      "2025-05-12 23:21:59,087 - INFO - SentenceTransformer - __init__ - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2025-05-12 23:22:02,151 - INFO - 2479983000 - initialize_query_embedding_model - Query embedding model loaded and using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2651965d43de4cc79f87347ecd69816d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 23:22:02,320 - INFO - 4042634767 - display_query_search_results - \n",
      "--- Results for query: 'What are the core courses for the MS in Applied Data Science?' ---\n",
      "2025-05-12 23:22:02,322 - INFO - 4042634767 - display_query_search_results - \n",
      "Result #1 (Distance: 0.4343):\n",
      "2025-05-12 23:22:02,323 - INFO - 4042634767 - display_query_search_results - Document: In-Person Program – DSI\n",
      "2025-05-12 23:22:02,325 - INFO - 4042634767 - display_query_search_results - Section: By and For Data Science Innovators\n",
      "2025-05-12 23:22:02,327 - INFO - 4042634767 - display_query_search_results - Subsection: Core Courses (6)\n",
      "2025-05-12 23:22:02,328 - INFO - 4042634767 - display_query_search_results - Content: ### Core Courses (6)\n",
      "\n",
      "You will complete six core courses toward your [Master’s in Applied Data Science](https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/) degree. Core courses allow you to build your theoretical data science knowledge and practice applying this ...\n",
      "2025-05-12 23:22:02,330 - INFO - 4042634767 - display_query_search_results - \n",
      "Result #2 (Distance: 0.4343):\n",
      "2025-05-12 23:22:02,331 - INFO - 4042634767 - display_query_search_results - Document: In-Person Program – DSI\n",
      "2025-05-12 23:22:02,332 - INFO - 4042634767 - display_query_search_results - Section: By and For Data Science Innovators\n",
      "2025-05-12 23:22:02,332 - INFO - 4042634767 - display_query_search_results - Subsection: Core Courses (6)\n",
      "2025-05-12 23:22:02,333 - INFO - 4042634767 - display_query_search_results - Content: ### Core Courses (6)\n",
      "\n",
      "You will complete six core courses toward your [Master’s in Applied Data Science](https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/) degree. Core courses allow you to build your theoretical data science knowledge and practice applying this ...\n",
      "2025-05-12 23:22:02,335 - INFO - 4042634767 - display_query_search_results - \n",
      "Result #3 (Distance: 0.4357):\n",
      "2025-05-12 23:22:02,336 - INFO - 4042634767 - display_query_search_results - Document: Online Program – DSI\n",
      "2025-05-12 23:22:02,337 - INFO - 4042634767 - display_query_search_results - Section: Curriculum\n",
      "2025-05-12 23:22:02,338 - INFO - 4042634767 - display_query_search_results - Subsection: Core Courses (6)\n",
      "2025-05-12 23:22:02,338 - INFO - 4042634767 - display_query_search_results - Content: ### Core Courses (6)\n",
      "\n",
      "You will complete 6 core courses toward your [Master’s in Applied Data Science](https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/instructors-staff/) degree. Core courses allow you to build your theoretical data science knowledge and practic...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2992a568c4d64a0da6c01fcee6c549f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 23:22:02,390 - INFO - 4042634767 - display_query_search_results - \n",
      "--- Results for query: 'Tell me about the faculty specializing in machine learning.' ---\n",
      "2025-05-12 23:22:02,391 - INFO - 4042634767 - display_query_search_results - \n",
      "Result #1 (Distance: 0.7109):\n",
      "2025-05-12 23:22:02,392 - INFO - 4042634767 - display_query_search_results - Document: Igor Yakushin, PhD\n",
      "2025-05-12 23:22:02,393 - INFO - 4042634767 - display_query_search_results - Content: People / MS Instructors\n",
      "\n",
      "# Igor Yakushin, PhD\n",
      "\n",
      "Instructor; Applied Scientist\n",
      "\n",
      "PhD in Theoretical Physics, MS in Computer Science. Currently – Applied Scientist at Amazon. Previous jobs: Computational Scientist at the Argonne National Laboratory, Scientist at LIGO project of California Institute of T...\n",
      "2025-05-12 23:22:02,394 - INFO - 4042634767 - display_query_search_results - \n",
      "Result #2 (Distance: 0.7915):\n",
      "2025-05-12 23:22:02,395 - INFO - 4042634767 - display_query_search_results - Document: Faculty, Instructors, Staff – DSI\n",
      "2025-05-12 23:22:02,396 - INFO - 4042634767 - display_query_search_results - Section: Faculty, Instructors, Staff\n",
      "2025-05-12 23:22:02,397 - INFO - 4042634767 - display_query_search_results - Subsection: None\n",
      "2025-05-12 23:22:02,398 - INFO - 4042634767 - display_query_search_results - Content: ## Faculty, Instructors, Staff\n",
      "\n",
      "As a Master’s in Applied Data Science student, [you will learn from faculty and instructors who are public- and private-sector leaders in emerging AI/AutoML technologie](https://www.youtube.com/watch?v=qfIRr0tu2RQ&list=PL0IrIAIuK93EonLgPKZ7oIcpt0p_j58vm&index=6)s. The...\n",
      "2025-05-12 23:22:02,399 - INFO - 4042634767 - display_query_search_results - \n",
      "Result #3 (Distance: 0.7998):\n",
      "2025-05-12 23:22:02,399 - INFO - 4042634767 - display_query_search_results - Document: Utku Pamuksuz, PhD\n",
      "2025-05-12 23:22:02,400 - INFO - 4042634767 - display_query_search_results - Content: People / MS Instructors\n",
      "\n",
      "# Utku Pamuksuz, PhD\n",
      "\n",
      "Associate Clinical Professor; Co-Founder Inference Analytics\n",
      "\n",
      "Dr. Pamuksuz, a professor of AI, specializes in applied mathematics, machine/deep learning, responsible and generative AI. He has contributed to various analytics journals, including IEEE Tra...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae9c7a1320c4ade918e782605857840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 23:22:02,431 - INFO - 4042634767 - display_query_search_results - \n",
      "--- Results for query: 'What are the admission requirements?' ---\n",
      "2025-05-12 23:22:02,432 - INFO - 4042634767 - display_query_search_results - \n",
      "Result #1 (Distance: 0.7672):\n",
      "2025-05-12 23:22:02,433 - INFO - 4042634767 - display_query_search_results - Document: How to Apply – DSI\n",
      "2025-05-12 23:22:02,433 - INFO - 4042634767 - display_query_search_results - Section: Master’s in Applied Data Science Application Requirements\n",
      "2025-05-12 23:22:02,434 - INFO - 4042634767 - display_query_search_results - Subsection: English Language Requirement\n",
      "2025-05-12 23:22:02,434 - INFO - 4042634767 - display_query_search_results - Content: ### English Language Requirement\n",
      "\n",
      "Applicants to the Master’s in Applied Data Science program who do not meet the English Language Proficiency criteria must submit proof of English language proficiency.\n",
      "\n",
      "Minimum scores for the Master’s in Applied Data Science program: TOEFL, 102 (no subscore requirem...\n",
      "2025-05-12 23:22:02,435 - INFO - 4042634767 - display_query_search_results - \n",
      "Result #2 (Distance: 0.8651):\n",
      "2025-05-12 23:22:02,435 - INFO - 4042634767 - display_query_search_results - Document: FAQs – DSI\n",
      "2025-05-12 23:22:02,436 - INFO - 4042634767 - display_query_search_results - Section: Unknown\n",
      "2025-05-12 23:22:02,436 - INFO - 4042634767 - display_query_search_results - Subsection: Are standardized tests required for admission?\n",
      "2025-05-12 23:22:02,437 - INFO - 4042634767 - display_query_search_results - Content: ### Are standardized tests required for admission?\n",
      "\n",
      "As part of the online application, candidates will be required to submit a GMAT or GRE score for the joint program. International applicants may be required to submit proof of English language proficiency by submitting a TOEFL iBT or IELTS test sco...\n",
      "2025-05-12 23:22:02,437 - INFO - 4042634767 - display_query_search_results - \n",
      "Result #3 (Distance: 0.9257):\n",
      "2025-05-12 23:22:02,438 - INFO - 4042634767 - display_query_search_results - Document: How to Apply – DSI\n",
      "2025-05-12 23:22:02,438 - INFO - 4042634767 - display_query_search_results - Section: Master’s in Applied Data Science Application Requirements\n",
      "2025-05-12 23:22:02,439 - INFO - 4042634767 - display_query_search_results - Subsection: None\n",
      "2025-05-12 23:22:02,439 - INFO - 4042634767 - display_query_search_results - Content: ## Master’s in Applied Data Science Application Requirements\n",
      "\n",
      "The [application portal](https://apply-psd.uchicago.edu/apply/) for entrance in Autumn 2025 is now open! Check out our blog post [here](https://datascience.uchicago.edu/news/applying-to-the-ms-in-applied-data-science-program-heres-what-we...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48cd3a52ffe4061bd4900e7ab4ea6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 23:22:02,463 - INFO - 4042634767 - display_query_search_results - \n",
      "--- Results for query: 'How is the capstone project structured?' ---\n",
      "2025-05-12 23:22:02,463 - INFO - 4042634767 - display_query_search_results - \n",
      "Result #1 (Distance: 0.6060):\n",
      "2025-05-12 23:22:02,464 - INFO - 4042634767 - display_query_search_results - Document: In-Person Program – DSI\n",
      "2025-05-12 23:22:02,465 - INFO - 4042634767 - display_query_search_results - Section: By and For Data Science Innovators\n",
      "2025-05-12 23:22:02,466 - INFO - 4042634767 - display_query_search_results - Subsection: Capstone (2)\n",
      "2025-05-12 23:22:02,466 - INFO - 4042634767 - display_query_search_results - Content: ### Capstone (2)\n",
      "\n",
      "The required [Capstone Project](https://datascience.uchicago.edu/capstone-projects/) is completed over two quarters and covers research design, implementation, and writing. Full-time students start their Capstone Project in their third quarter. Part-time students generally begin th...\n",
      "2025-05-12 23:22:02,467 - INFO - 4042634767 - display_query_search_results - \n",
      "Result #2 (Distance: 0.6060):\n",
      "2025-05-12 23:22:02,468 - INFO - 4042634767 - display_query_search_results - Document: In-Person Program – DSI\n",
      "2025-05-12 23:22:02,468 - INFO - 4042634767 - display_query_search_results - Section: By and For Data Science Innovators\n",
      "2025-05-12 23:22:02,469 - INFO - 4042634767 - display_query_search_results - Subsection: Capstone (2)\n",
      "2025-05-12 23:22:02,469 - INFO - 4042634767 - display_query_search_results - Content: ### Capstone (2)\n",
      "\n",
      "The required [Capstone Project](https://datascience.uchicago.edu/capstone-projects/) is completed over two quarters and covers research design, implementation, and writing. Full-time students start their Capstone Project in their third quarter. Part-time students generally begin th...\n",
      "2025-05-12 23:22:02,470 - INFO - 4042634767 - display_query_search_results - \n",
      "Result #3 (Distance: 0.7712):\n",
      "2025-05-12 23:22:02,470 - INFO - 4042634767 - display_query_search_results - Document: Master’s in Applied Data Science – DSI\n",
      "2025-05-12 23:22:02,470 - INFO - 4042634767 - display_query_search_results - Section: Data in Action - Capstone Projects\n",
      "2025-05-12 23:22:02,471 - INFO - 4042634767 - display_query_search_results - Subsection: None\n",
      "2025-05-12 23:22:02,472 - INFO - 4042634767 - display_query_search_results - Content: ## Data in Action - Capstone Projects\n",
      "\n",
      "Whether you are early in your career or more advanced, you will benefit from our real-world Capstone Experience. You will have the opportunity to help top companies across multiple sectors to solve real business problems. [Sample Capstone Projects](https://data...\n",
      "2025-05-12 23:22:02,472 - INFO - 914924386 - <module> - \n",
      "--- Testing Query with Metadata Filter (category: education) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f762f33854ea496587c63f74cc80bb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 23:22:02,542 - INFO - 4042634767 - display_query_search_results - \n",
      "--- Results for query: 'capstone project (filtered by category: education)' ---\n",
      "2025-05-12 23:22:02,543 - INFO - 4042634767 - display_query_search_results - \n",
      "Result #1 (Distance: 0.7351):\n",
      "2025-05-12 23:22:02,544 - INFO - 4042634767 - display_query_search_results - Document: In-Person Program – DSI\n",
      "2025-05-12 23:22:02,545 - INFO - 4042634767 - display_query_search_results - Section: By and For Data Science Innovators\n",
      "2025-05-12 23:22:02,546 - INFO - 4042634767 - display_query_search_results - Subsection: Capstone (2)\n",
      "2025-05-12 23:22:02,546 - INFO - 4042634767 - display_query_search_results - Content: ### Capstone (2)\n",
      "\n",
      "The required [Capstone Project](https://datascience.uchicago.edu/capstone-projects/) is completed over two quarters and covers research design, implementation, and writing. Full-time students start their Capstone Project in their third quarter. Part-time students generally begin th...\n",
      "2025-05-12 23:22:02,547 - INFO - 4042634767 - display_query_search_results - \n",
      "Result #2 (Distance: 0.7351):\n",
      "2025-05-12 23:22:02,548 - INFO - 4042634767 - display_query_search_results - Document: In-Person Program – DSI\n",
      "2025-05-12 23:22:02,548 - INFO - 4042634767 - display_query_search_results - Section: By and For Data Science Innovators\n",
      "2025-05-12 23:22:02,549 - INFO - 4042634767 - display_query_search_results - Subsection: Capstone (2)\n",
      "2025-05-12 23:22:02,549 - INFO - 4042634767 - display_query_search_results - Content: ### Capstone (2)\n",
      "\n",
      "The required [Capstone Project](https://datascience.uchicago.edu/capstone-projects/) is completed over two quarters and covers research design, implementation, and writing. Full-time students start their Capstone Project in their third quarter. Part-time students generally begin th...\n",
      "2025-05-12 23:22:02,550 - INFO - 914924386 - <module> - \n",
      "--- Testing Context Retrieval Function ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1129a8e3e7b4c6aafe20ffc0052dcf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 23:22:02,576 - INFO - 914924386 - <module> - \n",
      "Retrieved Context #1:\n",
      "Source 1: Online Program – DSI | Section: Curriculum | Subsection: Core Courses (6)\n",
      "\n",
      "### Core Courses (6)\n",
      "\n",
      "You will complete 6 core courses toward your [Master’s in Applied Data Science](https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/instructors-staff/) degree. Core courses allow you to build your theoretical data science knowledge and practice applying this theory to examine real-world business problems.\n",
      "\n",
      "2025-05-12 23:22:02,577 - INFO - 914924386 - <module> - \n",
      "Retrieved Context #2:\n",
      "Source 2: In-Person Program – DSI | Section: By and For Data Science Innovators | Subsection: Core Courses (6)\n",
      "\n",
      "### Core Courses (6)\n",
      "\n",
      "You will complete six core courses toward your [Master’s in Applied Data Science](https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/) degree. Core courses allow you to build your theoretical data science knowledge and practice applying this theory to examine real-world business problems.\n",
      "\n",
      "2025-05-12 23:22:02,578 - INFO - 914924386 - <module> - --- Vector Database Process Completed in 4.19 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "db_creation_start_time = time.time()\n",
    "\n",
    "logger.info(\"Starting vector database creation process\")\n",
    "\n",
    "# 1. Load the data\n",
    "ids, embeddings, documents, metadatas = load_data_for_chroma(CHUNKS_WITH_EMBEDDINGS_FILE)\n",
    "\n",
    "if ids:\n",
    "    # 2. Initialize ChromaDB\n",
    "    chroma_client, chroma_collection_instance = initialize_chroma_client_and_collection(\n",
    "        CHROMA_DB_DIR, COLLECTION_NAME\n",
    "    )\n",
    "    \n",
    "    if chroma_collection_instance:\n",
    "        # 3. Add data to ChromaDB\n",
    "        success = add_data_to_chroma_collection(\n",
    "            chroma_collection_instance, ids, embeddings, documents, metadatas\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            logger.info(f\"ChromaDB collection '{COLLECTION_NAME}' created successfully with {len(ids)} documents\")\n",
    "            \n",
    "            # 4. Initialize the embedding model for queries\n",
    "            query_model = initialize_query_embedding_model(QUERY_EMBEDDING_MODEL_NAME)\n",
    "            \n",
    "            if query_model:\n",
    "                # 5. Test some queries\n",
    "                sample_test_queries = [\n",
    "                    \"What are the core courses for the MS in Applied Data Science?\",\n",
    "                    \"Tell me about the faculty specializing in machine learning.\",\n",
    "                    \"What are the admission requirements?\",\n",
    "                    \"How is the capstone project structured?\"\n",
    "                ]\n",
    "                for test_q in sample_test_queries:\n",
    "                    results = query_chroma_collection(chroma_collection_instance, test_q, query_model, top_n_results=3)\n",
    "                    display_query_search_results(results, test_q)\n",
    "                \n",
    "                # Test with metadata filter (example)\n",
    "                if metadatas: # Check if metadatas list is not empty\n",
    "                    sample_category = metadatas[0].get('category')\n",
    "                    if sample_category:\n",
    "                        logger.info(f\"\\n--- Testing Query with Metadata Filter (category: {sample_category}) ---\")\n",
    "                        filtered_query = \"capstone project\"\n",
    "                        filter_criteria = {\"category\": sample_category} \n",
    "                        # Example of more complex filter: {\"$and\": [{\"category\": \"education\"}, {\"title\": {\"$contains\": \"Online\"}}]}\n",
    "                        \n",
    "                        filtered_results = query_chroma_collection(\n",
    "                            chroma_collection_instance, filtered_query, query_model, \n",
    "                            top_n_results=2, metadata_filter_dict=filter_criteria\n",
    "                        )\n",
    "                        display_query_search_results(filtered_results, f\"{filtered_query} (filtered by category: {sample_category})\")\n",
    "                    else:\n",
    "                        logger.info(\"Skipping metadata filter test as no sample category found in the first chunk.\")\n",
    "                \n",
    "                # 6. Test the context retrieval function\n",
    "                logger.info(\"\\n--- Testing Context Retrieval Function ---\")\n",
    "                retrieved_contexts = build_retrieval_context(\n",
    "                    \"What are the core courses?\", \n",
    "                    top_k_docs=2, \n",
    "                    collection_inst=chroma_collection_instance, # Pass instances\n",
    "                    query_embed_model_inst=query_model           # Pass instances\n",
    "                )\n",
    "                for i, ctx in enumerate(retrieved_contexts):\n",
    "                    logger.info(f\"\\nRetrieved Context #{i+1}:\\n{ctx}\")\n",
    "            else:\n",
    "                logger.error(\"Query embedding model could not be initialized. Query testing skipped.\")\n",
    "        else:\n",
    "            logger.error(\"Failed to add data to ChromaDB collection. Process halted.\")\n",
    "    else:\n",
    "        logger.error(\"ChromaDB collection could not be initialized. Process halted.\")\n",
    "else:\n",
    "    logger.error(f\"Failed to load data from {CHUNKS_WITH_EMBEDDINGS_FILE}. Process halted.\")\n",
    "\n",
    "db_creation_end_time = time.time()\n",
    "elapsed_processing_time = db_creation_end_time - db_creation_start_time\n",
    "logger.info(f\"--- Vector Database Process Completed in {elapsed_processing_time:.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
