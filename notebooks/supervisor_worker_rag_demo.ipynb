{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervisor-Worker RAG Chatbot Demonstration\n",
    "\n",
    "This notebook demonstrates the RAG (Retrieval-Augmented Generation) chatbot implementation using LangGraph with a Supervisor-Worker architecture. The chatbot is designed to answer questions about the University's MS in Applied Data Science program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the required libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Import our RAG chatbot implementation\n",
    "from src.rag_chatbot import RAGChatbot\n",
    "\n",
    "# For visualization\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set OpenAI API Key\n",
    "\n",
    "Make sure to set your OpenAI API key. You can either set it as an environment variable or directly in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì OPENAI_API_KEY is set!\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Set the API key directly (replace with your actual key)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_api_key\"\n",
    "\n",
    "# Option 2: Load from a .env file or check if already set\n",
    "#from dotenv import load_dotenv\n",
    "#load_dotenv()  # This will load environment variables from a .env file if present\n",
    "\n",
    "# Verify the API key is set\n",
    "if \"OPENAI_API_KEY\" not in os.environ or not os.environ[\"OPENAI_API_KEY\"]:\n",
    "    print(\"‚ö†Ô∏è Warning: OPENAI_API_KEY is not set. Please set it before proceeding.\")\n",
    "else:\n",
    "    print(\"‚úì OPENAI_API_KEY is set!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Chatbot\n",
    "\n",
    "Now let's initialize our RAG chatbot that uses the Supervisor-Worker architecture with LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Chatbot initialized!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the chatbot with GPT-3.5-Turbo\n",
    "# You can also use 'gpt-4' if you have access to it\n",
    "chatbot = RAGChatbot(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "print(\"RAG Chatbot initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the LangGraph Workflow\n",
    "\n",
    "Here we'll visualize the workflow using Mermaid chart representation (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not generate graph visualization: cannot import name 'get_graph_representation' from 'langgraph.graph' (c:\\Users\\alen.pavlovic\\Documents\\GitLab\\gen-ai-midterm-project\\ragchat\\Lib\\site-packages\\langgraph\\graph\\__init__.py)\n",
      "\n",
      "Fallback text representation:\n",
      "Supervisor ‚Üí Retrieve ‚Üí Generate ‚Üí Supervisor\n",
      "Supervisor ‚Üí Generate ‚Üí Supervisor\n",
      "Supervisor ‚Üí Summarize ‚Üí Done\n",
      "Supervisor ‚Üí Done\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Attempt to draw the graph if LangGraph supports it\n",
    "    from langgraph.graph import get_graph_representation, get_mermaid\n",
    "    \n",
    "    # Get the graph from our implementation\n",
    "    graph = chatbot.graph.graph\n",
    "    \n",
    "    # Generate mermaid representation\n",
    "    mermaid_representation = get_mermaid(graph)\n",
    "    \n",
    "    # Display as mermaid diagram\n",
    "    display(HTML(f\"\"\"\n",
    "    <div class=\"mermaid\">\n",
    "    {mermaid_representation}\n",
    "    </div>\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js\"></script>\n",
    "    <script>mermaid.initialize({{startOnLoad:true}});</script>\n",
    "    \"\"\"))\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate graph visualization: {e}\")\n",
    "    print(\"\\nFallback text representation:\")\n",
    "    print(\"Supervisor ‚Üí Retrieve ‚Üí Generate ‚Üí Supervisor\")\n",
    "    print(\"Supervisor ‚Üí Generate ‚Üí Supervisor\")\n",
    "    print(\"Supervisor ‚Üí Summarize ‚Üí Done\")\n",
    "    print(\"Supervisor ‚Üí Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the RAG Chatbot\n",
    "\n",
    "Let's test our chatbot with some sample questions about the MS in Applied Data Science program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatted_chat(query, stream=False):\n",
    "    \"\"\"Format the chat nicely for display\"\"\"\n",
    "    print(f\"üßë User: {query}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Get the response\n",
    "    try:\n",
    "        if stream:\n",
    "            response, steps = chatbot.chat(query, stream=True)\n",
    "        else:\n",
    "            response = chatbot.chat(query)\n",
    "            \n",
    "        # Format the response appropriately\n",
    "        if isinstance(response, list) and len(response) > 0:\n",
    "            if isinstance(response[-1], dict):\n",
    "                print(f\"ü§ñ Assistant: {response[-1].get('content', 'No content')}\\n\")\n",
    "            else:\n",
    "                print(f\"ü§ñ Assistant: {response}\\n\")\n",
    "        else:\n",
    "            print(f\"ü§ñ Assistant: {response}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßë User: What is the MS in Applied Data Science program about?\n",
      "\n",
      "\n",
      "ü§ñ Assistant: Concise Answer: The MS in Applied Data Science program focuses on training students in practical applications of data science for solving real-world problems.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Concise Answer: The MS in Applied Data Science program focuses on training students in practical applications of data science for solving real-world problems.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1: Basic program information\n",
    "query1 = \"What is the MS in Applied Data Science program about?\"\n",
    "formatted_chat(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßë User: What are the core courses for the program?\n",
      "\n",
      "\n",
      "Retrieved existing collection 'ms_applied_data_science'\n",
      "ü§ñ Assistant: The core courses for the Master's in Applied Data Science program consist of 6 courses. These core courses are designed to help students build their theoretical data science knowledge and apply this theory to analyze real-world business problems. In addition to the core courses, students are also required to complete 4 elective courses and 2 Capstone projects as part of the rigorous curriculum. The curriculum is regularly reviewed to ensure that it aligns with the evolving landscape of data science.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The core courses for the Master's in Applied Data Science program consist of 6 courses. These core courses are designed to help students build their theoretical data science knowledge and apply this theory to analyze real-world business problems. In addition to the core courses, students are also required to complete 4 elective courses and 2 Capstone projects as part of the rigorous curriculum. The curriculum is regularly reviewed to ensure that it aligns with the evolving landscape of data science.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2: Course requirements\n",
    "query2 = \"What are the core courses for the program?\"\n",
    "formatted_chat(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Follow-up question (demonstrates conversation memory)\n",
    "query3 = \"How long does it take to complete these courses?\"\n",
    "formatted_chat(query3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Question requiring summarization (potentially lengthy answer)\n",
    "query4 = \"What career opportunities are available after completing this program? Please provide detailed examples.\"\n",
    "formatted_chat(query4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Mode with Step-by-Step Execution\n",
    "\n",
    "For debugging purposes, we can run the chatbot in streaming mode to see the step-by-step execution of the LangGraph workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream mode with detailed steps\n",
    "debug_query = \"What are the admission requirements for the program?\"\n",
    "formatted_chat(debug_query, stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset Conversation\n",
    "\n",
    "We can reset the conversation history if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the conversation\n",
    "chatbot.reset()\n",
    "print(\"Conversation has been reset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn Conversation Test\n",
    "\n",
    "Let's test a multi-turn conversation to see how the chatbot maintains context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new conversation after reset\n",
    "formatted_chat(\"Tell me about the online program options.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up question\n",
    "formatted_chat(\"What's the difference between online and on-campus programs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another follow-up\n",
    "formatted_chat(\"Do online students get the same degree?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Conversation History\n",
    "\n",
    "We can view the full conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the conversation history\n",
    "history = chatbot.get_conversation_history()\n",
    "\n",
    "# Display it nicely\n",
    "for i, message in enumerate(history):\n",
    "    role = message[\"role\"]\n",
    "    content = message[\"content\"]\n",
    "    \n",
    "    if role == \"user\":\n",
    "        print(f\"Message {i+1} - üßë User: {content[:50]}...\" if len(content) > 50 else f\"Message {i+1} - üßë User: {content}\")\n",
    "    else:\n",
    "        print(f\"Message {i+1} - ü§ñ Assistant: {content[:50]}...\" if len(content) > 50 else f\"Message {i+1} - ü§ñ Assistant: {content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
