{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Vector Database with ChromaDB\n",
    "\n",
    "This notebook implements a vector database using ChromaDB to store and efficiently retrieve the embeddings we generated in the previous step. ChromaDB is a lightweight, embedded vector database that works well for RAG applications and doesn't require any external services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Import ChromaDB\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# For visualization and testing\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Paths\n",
    "\n",
    "First, let's define the paths for input embeddings and the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "EMBEDDINGS_DIR = \"../data/embeddings\"  # Directory with stored embeddings\n",
    "CHROMA_DIR = \"../data/chroma_db\"  # Directory to store ChromaDB files\n",
    "\n",
    "# Paths to the embedding files\n",
    "EMBEDDINGS_JSON = os.path.join(EMBEDDINGS_DIR, \"chunks_with_embeddings.json\")\n",
    "EMBEDDINGS_PKL = os.path.join(EMBEDDINGS_DIR, \"chunks_with_embeddings.pkl\")\n",
    "EMBEDDINGS_NPY = os.path.join(EMBEDDINGS_DIR, \"embeddings.npy\")\n",
    "METADATA_JSON = os.path.join(EMBEDDINGS_DIR, \"metadata.json\")\n",
    "\n",
    "# Create ChromaDB directory if it doesn't exist\n",
    "os.makedirs(CHROMA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embeddings and Metadata\n",
    "\n",
    "Now we'll load the embeddings and metadata we generated in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_and_metadata():\n",
    "    \"\"\"\n",
    "    Load the pre-generated embeddings and metadata from files.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (embeddings_array, metadata_list, documents_list)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the embeddings NumPy array\n",
    "        embeddings_array = np.load(EMBEDDINGS_NPY)\n",
    "        print(f\"Loaded embeddings array with shape: {embeddings_array.shape}\")\n",
    "        \n",
    "        # Load the metadata JSON\n",
    "        with open(METADATA_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "            metadata_list = json.load(f)\n",
    "        print(f\"Loaded metadata for {len(metadata_list)} chunks\")\n",
    "        \n",
    "        # Extract documents (text content) and clean metadata for ChromaDB\n",
    "        documents_list = [item[\"content\"] for item in metadata_list]\n",
    "        \n",
    "        # ChromaDB metadata must be simple types (string, int, float, bool)\n",
    "        clean_metadata = []\n",
    "        for item in metadata_list:\n",
    "            # Create a clean metadata dict with only simple types\n",
    "            clean_item = {\n",
    "                \"chunk_id\": str(item[\"chunk_id\"]),\n",
    "                \"source\": item.get(\"filename\", \"\"),\n",
    "                \"title\": item.get(\"title\", \"\"),\n",
    "                \"category\": item.get(\"category\", \"\"),\n",
    "                \"section\": item.get(\"section\", \"\")\n",
    "            }\n",
    "            clean_metadata.append(clean_item)\n",
    "            \n",
    "        return embeddings_array, clean_metadata, documents_list\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: File not found. {e}\")\n",
    "        print(\"Please run the embedding generation notebook first.\")\n",
    "        return None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading embeddings: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Load the embeddings and metadata\n",
    "embeddings_array, metadata_list, documents_list = load_embeddings_and_metadata()\n",
    "\n",
    "# Show a sample of the data\n",
    "if embeddings_array is not None:\n",
    "    print(\"\\nSample metadata item:\")\n",
    "    print(json.dumps(metadata_list[0], indent=2))\n",
    "    \n",
    "    print(\"\\nSample document content (truncated):\")\n",
    "    print(documents_list[0][:200] + \"...\" if len(documents_list[0]) > 200 else documents_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize ChromaDB\n",
    "\n",
    "Now let's initialize ChromaDB and create a collection for our embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_chroma_db():\n",
    "    \"\"\"\n",
    "    Initialize ChromaDB client and create a collection.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (chroma_client, chroma_collection)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a persistent client\n",
    "        client = chromadb.PersistentClient(path=CHROMA_DIR)\n",
    "        print(f\"Initialized ChromaDB client with persistent storage at {CHROMA_DIR}\")\n",
    "        \n",
    "        # Check if our collection already exists and recreate it\n",
    "        collection_name = \"ms_applied_data_science\"\n",
    "        try:\n",
    "            # Try to get existing collection\n",
    "            client.get_collection(collection_name)\n",
    "            # If it exists, delete it to start fresh\n",
    "            client.delete_collection(collection_name)\n",
    "            print(f\"Deleted existing collection '{collection_name}' to start fresh\")\n",
    "        except Exception:\n",
    "            # Collection doesn't exist yet\n",
    "            pass\n",
    "            \n",
    "        # Create a new collection with our custom embeddings\n",
    "        collection = client.create_collection(\n",
    "            name=collection_name,\n",
    "            metadata={\"description\": \"University of Chicago MS in Applied Data Science program content\"}\n",
    "        )\n",
    "        print(f\"Created collection '{collection_name}'\")\n",
    "        \n",
    "        return client, collection\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing ChromaDB: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Initialize ChromaDB\n",
    "chroma_client, chroma_collection = initialize_chroma_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Embeddings to ChromaDB\n",
    "\n",
    "Now let's add our pre-computed embeddings to the ChromaDB collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings_to_chroma(collection, embeddings, metadata, documents):\n",
    "    \"\"\"\n",
    "    Add pre-computed embeddings to ChromaDB collection.\n",
    "    \n",
    "    Args:\n",
    "        collection: ChromaDB collection\n",
    "        embeddings: NumPy array of embeddings\n",
    "        metadata: List of metadata dictionaries\n",
    "        documents: List of text documents (chunk content)\n",
    "        \n",
    "    Returns:\n",
    "        bool: Success status\n",
    "    \"\"\"\n",
    "    if collection is None or embeddings is None:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Create IDs for each document\n",
    "        ids = [f\"chunk_{i}\" for i in range(len(documents))]\n",
    "        \n",
    "        # Add in batches to avoid memory issues with large datasets\n",
    "        batch_size = 100\n",
    "        total_batches = (len(documents) + batch_size - 1) // batch_size\n",
    "        \n",
    "        for i in tqdm(range(0, len(documents), batch_size), desc=\"Adding to ChromaDB\", total=total_batches):\n",
    "            # Get the current batch\n",
    "            end_idx = min(i + batch_size, len(documents))\n",
    "            batch_ids = ids[i:end_idx]\n",
    "            batch_embeddings = embeddings[i:end_idx].tolist()\n",
    "            batch_documents = documents[i:end_idx]\n",
    "            batch_metadata = metadata[i:end_idx]\n",
    "            \n",
    "            # Add the batch to the collection\n",
    "            collection.add(\n",
    "                ids=batch_ids,\n",
    "                embeddings=batch_embeddings,\n",
    "                documents=batch_documents,\n",
    "                metadatas=batch_metadata\n",
    "            )\n",
    "        \n",
    "        print(f\"Successfully added {len(documents)} documents with embeddings to ChromaDB\")\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error adding embeddings to ChromaDB: {e}\")\n",
    "        return False\n",
    "\n",
    "# Add embeddings to ChromaDB\n",
    "success = add_embeddings_to_chroma(\n",
    "    chroma_collection, \n",
    "    embeddings_array, \n",
    "    metadata_list, \n",
    "    documents_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the Vector Database\n",
    "\n",
    "Now let's create functions to query our vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_embedding_model(model_name=\"all-MiniLM-L6-v2\"):\n",
    "    \"\"\"\n",
    "    Initialize the Sentence Transformer model for query embedding.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Name of the model to use\n",
    "        \n",
    "    Returns:\n",
    "        SentenceTransformer: Loaded model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = SentenceTransformer(model_name)\n",
    "        print(f\"Loaded Sentence Transformer model: {model_name}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Initialize the embedding model for queries\n",
    "embedding_model = initialize_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vector_database(collection, query_text, embedding_model, top_k=5, filter_dict=None):\n",
    "    \"\"\"\n",
    "    Query the vector database for similar documents.\n",
    "    \n",
    "    Args:\n",
    "        collection: ChromaDB collection\n",
    "        query_text (str): The query text\n",
    "        embedding_model: Model to create query embedding\n",
    "        top_k (int): Number of results to return\n",
    "        filter_dict (dict): Optional metadata filters\n",
    "        \n",
    "    Returns:\n",
    "        dict: Query results\n",
    "    \"\"\"\n",
    "    if collection is None or embedding_model is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Generate embedding for the query\n",
    "        query_embedding = embedding_model.encode(query_text).tolist()\n",
    "        \n",
    "        # Query the collection\n",
    "        results = collection.query(\n",
    "            query_embeddings=query_embedding,\n",
    "            n_results=top_k,\n",
    "            where=filter_dict  # Optional filtering by metadata\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying database: {e}\")\n",
    "        return None\n",
    "\n",
    "def display_query_results(results, query):\n",
    "    \"\"\"\n",
    "    Display the query results in a readable format.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): Results from ChromaDB query\n",
    "        query (str): The original query\n",
    "    \"\"\"\n",
    "    if results is None or len(results[\"ids\"]) == 0:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i in range(len(results[\"ids\"][0])):\n",
    "        doc_id = results[\"ids\"][0][i]\n",
    "        document = results[\"documents\"][0][i]\n",
    "        metadata = results[\"metadatas\"][0][i]\n",
    "        distance = results[\"distances\"][0][i] if \"distances\" in results else None\n",
    "        \n",
    "        print(f\"Result #{i+1} - ID: {doc_id}\")\n",
    "        if distance is not None:\n",
    "            print(f\"Relevance: {1 - distance:.4f}\")  # Convert distance to similarity score\n",
    "        \n",
    "        # Display metadata\n",
    "        source = metadata.get(\"source\", \"Unknown\")\n",
    "        title = metadata.get(\"title\", \"Unknown\")\n",
    "        category = metadata.get(\"category\", \"\")\n",
    "        print(f\"Source: {source}\")\n",
    "        print(f\"Title: {title}\")\n",
    "        if category:\n",
    "            print(f\"Category: {category}\")\n",
    "        \n",
    "        # Display content (truncated if long)\n",
    "        content_preview = document[:300] + \"...\" if len(document) > 300 else document\n",
    "        print(f\"Content:\\n{content_preview}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Queries\n",
    "\n",
    "Let's test our vector database with some sample queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of sample queries to test\n",
    "test_queries = [\n",
    "    \"What courses are required for the MS in Applied Data Science?\",\n",
    "    #\"Who are the faculty members in the program?\",\n",
    "    #\"How long does it take to complete the degree?\",\n",
    "    #\"What are the prerequisites for the program?\",\n",
    "    #\"Tell me about the capstone project requirements\"\n",
    "]\n",
    "\n",
    "# Test each query\n",
    "for query in test_queries:\n",
    "    print(f\"\\nTesting query: {query}\")\n",
    "    results = query_vector_database(chroma_collection, query, embedding_model, top_k=3)\n",
    "    display_query_results(results, query)\n",
    "    print(\"\\n\" + \"=\" * 100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering by Metadata\n",
    "\n",
    "One advantage of ChromaDB is the ability to filter results by metadata. Let's try some filtered queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values for some metadata fields\n",
    "if chroma_collection is not None:\n",
    "    # Get all metadata\n",
    "    all_metadata = chroma_collection.get(include=[\"metadatas\"])[\"metadatas\"]\n",
    "    \n",
    "    # Extract unique categories and sources\n",
    "    categories = set()\n",
    "    sources = set()\n",
    "    \n",
    "    for meta in all_metadata:\n",
    "        if \"category\" in meta and meta[\"category\"]:\n",
    "            categories.add(meta[\"category\"])\n",
    "        if \"source\" in meta and meta[\"source\"]:\n",
    "            sources.add(meta[\"source\"])\n",
    "    \n",
    "    print(\"Available categories:\")\n",
    "    for category in sorted(categories):\n",
    "        print(f\"- {category}\")\n",
    "        \n",
    "    print(\"\\nAvailable sources (sample):\")\n",
    "    for source in sorted(list(sources)[:5]):  # Show just a few sources\n",
    "        print(f\"- {source}\")\n",
    "    if len(sources) > 5:\n",
    "        print(f\"... and {len(sources) - 5} more sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try some filtered queries\n",
    "filtered_queries = [\n",
    "    (\"What are the core courses?\", {\"category\": \"education\"}),\n",
    "    (\"Who are the instructors?\", {\"category\": \"education\"})\n",
    "]\n",
    "\n",
    "for query, filter_dict in filtered_queries:\n",
    "    print(f\"\\nFiltered query: '{query}' with filter: {filter_dict}\")\n",
    "    results = query_vector_database(\n",
    "        chroma_collection, \n",
    "        query, \n",
    "        embedding_model, \n",
    "        top_k=3, \n",
    "        filter_dict=filter_dict\n",
    "    )\n",
    "    display_query_results(results, query)\n",
    "    print(\"\\n\" + \"=\" * 100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Simple Retrieval Function\n",
    "\n",
    "Finally, let's create a simple retrieval function that can be used in a RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query, top_k=5, filter_dict=None):\n",
    "    \"\"\"\n",
    "    Retrieve relevant context for a given query.\n",
    "    This function can be used as part of a RAG system.\n",
    "    \n",
    "    Args:\n",
    "        query (str): User query\n",
    "        top_k (int): Number of results to retrieve\n",
    "        filter_dict (dict): Optional metadata filters\n",
    "        \n",
    "    Returns:\n",
    "        list: List of context strings with source information\n",
    "    \"\"\"\n",
    "    # Query the vector database\n",
    "    results = query_vector_database(\n",
    "        chroma_collection,\n",
    "        query,\n",
    "        embedding_model,\n",
    "        top_k=top_k,\n",
    "        filter_dict=filter_dict\n",
    "    )\n",
    "    \n",
    "    if results is None or len(results[\"ids\"]) == 0:\n",
    "        return [\"No relevant information found.\"]\n",
    "    \n",
    "    # Format the retrieved context\n",
    "    context_list = []\n",
    "    for i in range(len(results[\"ids\"][0])):\n",
    "        document = results[\"documents\"][0][i]\n",
    "        metadata = results[\"metadatas\"][0][i]\n",
    "        \n",
    "        # Add source information\n",
    "        source = metadata.get(\"source\", \"Unknown source\")\n",
    "        title = metadata.get(\"title\", \"\")\n",
    "        source_info = f\"[Source: {source}\" + (f\", {title}\" if title else \"\") + \"]\"\n",
    "        \n",
    "        # Add the formatted context\n",
    "        context_list.append(f\"{document}\\n{source_info}\")\n",
    "    \n",
    "    return context_list\n",
    "\n",
    "# Example of how to use the retrieve_context function\n",
    "#query = \"What are the course requirements for the MS in Applied Data Science program?\"\n",
    "query = \"What are the core courses?\"\n",
    "retrieved_context = retrieve_context(query, top_k=3)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(\"\\nRetrieved context:\")\n",
    "for i, context in enumerate(retrieved_context):\n",
    "    print(f\"\\nContext {i+1}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(context)\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
