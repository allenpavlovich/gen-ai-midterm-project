{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Vector Database with ChromaDB\n",
    "\n",
    "This notebook implements a vector database using ChromaDB to store and efficiently retrieve the embeddings we generated in the previous step. ChromaDB is a lightweight, embedded vector database that works well for RAG applications and doesn't require any external services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Import ChromaDB\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# For visualization and testing\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Paths\n",
    "\n",
    "First, let's define the paths for input embeddings and the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "EMBEDDINGS_DIR = \"../data/embeddings\"  # Directory with stored embeddings\n",
    "CHROMA_DIR = \"../data/chroma_db\"  # Directory to store ChromaDB files\n",
    "\n",
    "# Paths to the embedding files\n",
    "EMBEDDINGS_JSON = os.path.join(EMBEDDINGS_DIR, \"chunks_with_embeddings.json\")\n",
    "EMBEDDINGS_PKL = os.path.join(EMBEDDINGS_DIR, \"chunks_with_embeddings.pkl\")\n",
    "EMBEDDINGS_NPY = os.path.join(EMBEDDINGS_DIR, \"embeddings.npy\")\n",
    "METADATA_JSON = os.path.join(EMBEDDINGS_DIR, \"metadata.json\")\n",
    "\n",
    "# Create ChromaDB directory if it doesn't exist\n",
    "os.makedirs(CHROMA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embeddings and Metadata\n",
    "\n",
    "Now we'll load the embeddings and metadata we generated in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings array with shape: (389, 384)\n",
      "Loaded metadata for 389 chunks\n",
      "\n",
      "Sample metadata item:\n",
      "{\n",
      "  \"chunk_id\": \"0\",\n",
      "  \"source\": \"education_masters-programs_ms-in-applied-data-science_course-progressions.md\",\n",
      "  \"title\": \"Course Progressions \\u2013 DSI\",\n",
      "  \"category\": \"education\",\n",
      "  \"section\": \"\"\n",
      "}\n",
      "\n",
      "Sample document content (truncated):\n",
      "## MS in Applied Data Science facet-arrow-down\n"
     ]
    }
   ],
   "source": [
    "def load_embeddings_and_metadata():\n",
    "    \"\"\"\n",
    "    Load the pre-generated embeddings and metadata from files.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (embeddings_array, metadata_list, documents_list)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the embeddings NumPy array\n",
    "        embeddings_array = np.load(EMBEDDINGS_NPY)\n",
    "        print(f\"Loaded embeddings array with shape: {embeddings_array.shape}\")\n",
    "        \n",
    "        # Load the metadata JSON\n",
    "        with open(METADATA_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "            metadata_list = json.load(f)\n",
    "        print(f\"Loaded metadata for {len(metadata_list)} chunks\")\n",
    "        \n",
    "        # Extract documents (text content) and clean metadata for ChromaDB\n",
    "        documents_list = [item[\"content\"] for item in metadata_list]\n",
    "        \n",
    "        # ChromaDB metadata must be simple types (string, int, float, bool)\n",
    "        clean_metadata = []\n",
    "        for item in metadata_list:\n",
    "            # Create a clean metadata dict with only simple types\n",
    "            clean_item = {\n",
    "                \"chunk_id\": str(item[\"chunk_id\"]),\n",
    "                \"source\": item.get(\"filename\", \"\"),\n",
    "                \"title\": item.get(\"title\", \"\"),\n",
    "                \"category\": item.get(\"category\", \"\"),\n",
    "                \"section\": item.get(\"section\", \"\")\n",
    "            }\n",
    "            clean_metadata.append(clean_item)\n",
    "            \n",
    "        return embeddings_array, clean_metadata, documents_list\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: File not found. {e}\")\n",
    "        print(\"Please run the embedding generation notebook first.\")\n",
    "        return None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading embeddings: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Load the embeddings and metadata\n",
    "embeddings_array, metadata_list, documents_list = load_embeddings_and_metadata()\n",
    "\n",
    "# Show a sample of the data\n",
    "if embeddings_array is not None:\n",
    "    print(\"\\nSample metadata item:\")\n",
    "    print(json.dumps(metadata_list[0], indent=2))\n",
    "    \n",
    "    print(\"\\nSample document content (truncated):\")\n",
    "    print(documents_list[0][:200] + \"...\" if len(documents_list[0]) > 200 else documents_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize ChromaDB\n",
    "\n",
    "Now let's initialize ChromaDB and create a collection for our embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized ChromaDB client with persistent storage at ../data/chroma_db\n",
      "Created collection 'ms_applied_data_science'\n"
     ]
    }
   ],
   "source": [
    "def initialize_chroma_db():\n",
    "    \"\"\"\n",
    "    Initialize ChromaDB client and create a collection.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (chroma_client, chroma_collection)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a persistent client\n",
    "        client = chromadb.PersistentClient(path=CHROMA_DIR)\n",
    "        print(f\"Initialized ChromaDB client with persistent storage at {CHROMA_DIR}\")\n",
    "        \n",
    "        # Check if our collection already exists and recreate it\n",
    "        collection_name = \"ms_applied_data_science\"\n",
    "        try:\n",
    "            # Try to get existing collection\n",
    "            client.get_collection(collection_name)\n",
    "            # If it exists, delete it to start fresh\n",
    "            client.delete_collection(collection_name)\n",
    "            print(f\"Deleted existing collection '{collection_name}' to start fresh\")\n",
    "        except Exception:\n",
    "            # Collection doesn't exist yet\n",
    "            pass\n",
    "            \n",
    "        # Create a new collection with our custom embeddings\n",
    "        collection = client.create_collection(\n",
    "            name=collection_name,\n",
    "            metadata={\"description\": \"University of Chicago MS in Applied Data Science program content\"}\n",
    "        )\n",
    "        print(f\"Created collection '{collection_name}'\")\n",
    "        \n",
    "        return client, collection\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing ChromaDB: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Initialize ChromaDB\n",
    "chroma_client, chroma_collection = initialize_chroma_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Embeddings to ChromaDB\n",
    "\n",
    "Now let's add our pre-computed embeddings to the ChromaDB collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f5ea3133b448948424927a8f1af302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding to ChromaDB:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 389 documents with embeddings to ChromaDB\n"
     ]
    }
   ],
   "source": [
    "def add_embeddings_to_chroma(collection, embeddings, metadata, documents):\n",
    "    \"\"\"\n",
    "    Add pre-computed embeddings to ChromaDB collection.\n",
    "    \n",
    "    Args:\n",
    "        collection: ChromaDB collection\n",
    "        embeddings: NumPy array of embeddings\n",
    "        metadata: List of metadata dictionaries\n",
    "        documents: List of text documents (chunk content)\n",
    "        \n",
    "    Returns:\n",
    "        bool: Success status\n",
    "    \"\"\"\n",
    "    if collection is None or embeddings is None:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Create IDs for each document\n",
    "        ids = [f\"chunk_{i}\" for i in range(len(documents))]\n",
    "        \n",
    "        # Add in batches to avoid memory issues with large datasets\n",
    "        batch_size = 100\n",
    "        total_batches = (len(documents) + batch_size - 1) // batch_size\n",
    "        \n",
    "        for i in tqdm(range(0, len(documents), batch_size), desc=\"Adding to ChromaDB\", total=total_batches):\n",
    "            # Get the current batch\n",
    "            end_idx = min(i + batch_size, len(documents))\n",
    "            batch_ids = ids[i:end_idx]\n",
    "            batch_embeddings = embeddings[i:end_idx].tolist()\n",
    "            batch_documents = documents[i:end_idx]\n",
    "            batch_metadata = metadata[i:end_idx]\n",
    "            \n",
    "            # Add the batch to the collection\n",
    "            collection.add(\n",
    "                ids=batch_ids,\n",
    "                embeddings=batch_embeddings,\n",
    "                documents=batch_documents,\n",
    "                metadatas=batch_metadata\n",
    "            )\n",
    "        \n",
    "        print(f\"Successfully added {len(documents)} documents with embeddings to ChromaDB\")\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error adding embeddings to ChromaDB: {e}\")\n",
    "        return False\n",
    "\n",
    "# Add embeddings to ChromaDB\n",
    "success = add_embeddings_to_chroma(\n",
    "    chroma_collection, \n",
    "    embeddings_array, \n",
    "    metadata_list, \n",
    "    documents_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the Vector Database\n",
    "\n",
    "Now let's create functions to query our vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Sentence Transformer model: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "def initialize_embedding_model(model_name=\"all-MiniLM-L6-v2\"):\n",
    "    \"\"\"\n",
    "    Initialize the Sentence Transformer model for query embedding.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Name of the model to use\n",
    "        \n",
    "    Returns:\n",
    "        SentenceTransformer: Loaded model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = SentenceTransformer(model_name)\n",
    "        print(f\"Loaded Sentence Transformer model: {model_name}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Initialize the embedding model for queries\n",
    "embedding_model = initialize_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vector_database(collection, query_text, embedding_model, top_k=5, filter_dict=None):\n",
    "    \"\"\"\n",
    "    Query the vector database for similar documents.\n",
    "    \n",
    "    Args:\n",
    "        collection: ChromaDB collection\n",
    "        query_text (str): The query text\n",
    "        embedding_model: Model to create query embedding\n",
    "        top_k (int): Number of results to return\n",
    "        filter_dict (dict): Optional metadata filters\n",
    "        \n",
    "    Returns:\n",
    "        dict: Query results\n",
    "    \"\"\"\n",
    "    if collection is None or embedding_model is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Generate embedding for the query\n",
    "        query_embedding = embedding_model.encode(query_text).tolist()\n",
    "        \n",
    "        # Query the collection\n",
    "        results = collection.query(\n",
    "            query_embeddings=query_embedding,\n",
    "            n_results=top_k,\n",
    "            where=filter_dict  # Optional filtering by metadata\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying database: {e}\")\n",
    "        return None\n",
    "\n",
    "def display_query_results(results, query):\n",
    "    \"\"\"\n",
    "    Display the query results in a readable format.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): Results from ChromaDB query\n",
    "        query (str): The original query\n",
    "    \"\"\"\n",
    "    if results is None or len(results[\"ids\"]) == 0:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i in range(len(results[\"ids\"][0])):\n",
    "        doc_id = results[\"ids\"][0][i]\n",
    "        document = results[\"documents\"][0][i]\n",
    "        metadata = results[\"metadatas\"][0][i]\n",
    "        distance = results[\"distances\"][0][i] if \"distances\" in results else None\n",
    "        \n",
    "        print(f\"Result #{i+1} - ID: {doc_id}\")\n",
    "        if distance is not None:\n",
    "            print(f\"Relevance: {1 - distance:.4f}\")  # Convert distance to similarity score\n",
    "        \n",
    "        # Display metadata\n",
    "        source = metadata.get(\"source\", \"Unknown\")\n",
    "        title = metadata.get(\"title\", \"Unknown\")\n",
    "        category = metadata.get(\"category\", \"\")\n",
    "        print(f\"Source: {source}\")\n",
    "        print(f\"Title: {title}\")\n",
    "        if category:\n",
    "            print(f\"Category: {category}\")\n",
    "        \n",
    "        # Display content (truncated if long)\n",
    "        content_preview = document[:300] + \"...\" if len(document) > 300 else document\n",
    "        print(f\"Content:\\n{content_preview}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Queries\n",
    "\n",
    "Let's test our vector database with some sample queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing query: What courses are required for the MS in Applied Data Science?\n",
      "Query: What courses are required for the MS in Applied Data Science?\n",
      "--------------------------------------------------------------------------------\n",
      "Result #1 - ID: chunk_276\n",
      "Relevance: 0.3835\n",
      "Source: education_masters-programs_ms-in-applied-data-science_online-program.md\n",
      "Title: Online Program – DSI\n",
      "Category: education\n",
      "Content:\n",
      "You have the flexibility to pursue the [Master’s in Applied Data Science](https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/) degree on a part- or full-time schedule. Part-time students enroll in two courses each quarter and take their courses in the evenings or ...\n",
      "--------------------------------------------------------------------------------\n",
      "Result #2 - ID: chunk_283\n",
      "Relevance: 0.3594\n",
      "Source: education_masters-programs_ms-in-applied-data-science_online-program.md\n",
      "Title: Online Program – DSI\n",
      "Category: education\n",
      "Content:\n",
      "### Core Courses (6)\n",
      "\n",
      "You will complete 6 core courses toward your [Master’s in Applied Data Science](https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/instructors-staff/) degree. Core courses allow you to build your theoretical data science knowledge and practic...\n",
      "--------------------------------------------------------------------------------\n",
      "Result #3 - ID: chunk_277\n",
      "Relevance: 0.3238\n",
      "Source: education_masters-programs_ms-in-applied-data-science_online-program.md\n",
      "Title: Online Program – DSI\n",
      "Category: education\n",
      "Content:\n",
      "Foundational noncredit courses are designed and taught by Master’s in Applied Data Science [faculty and instructors](https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/instructors-staff/). These optional courses—available at no additional cost— provide the basis f...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of sample queries to test\n",
    "test_queries = [\n",
    "    \"What courses are required for the MS in Applied Data Science?\",\n",
    "    #\"Who are the faculty members in the program?\",\n",
    "    #\"How long does it take to complete the degree?\",\n",
    "    #\"What are the prerequisites for the program?\",\n",
    "    #\"Tell me about the capstone project requirements\"\n",
    "]\n",
    "\n",
    "# Test each query\n",
    "for query in test_queries:\n",
    "    print(f\"\\nTesting query: {query}\")\n",
    "    results = query_vector_database(chroma_collection, query, embedding_model, top_k=3)\n",
    "    display_query_results(results, query)\n",
    "    print(\"\\n\" + \"=\" * 100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering by Metadata\n",
    "\n",
    "One advantage of ChromaDB is the ability to filter results by metadata. Let's try some filtered queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available categories:\n",
      "- education\n",
      "\n",
      "Available sources (sample):\n",
      "- education_masters-programs_ms-in-applied-data-science_course-progressions.md\n",
      "- education_masters-programs_ms-in-applied-data-science_instructors-staff.md\n",
      "- education_masters-programs_ms-in-applied-data-science_online-program.md\n",
      "- education_masters-programs_ms-in-applied-data-science_tuition-fees-aid.md\n"
     ]
    }
   ],
   "source": [
    "# Get unique values for some metadata fields\n",
    "if chroma_collection is not None:\n",
    "    # Get all metadata\n",
    "    all_metadata = chroma_collection.get(include=[\"metadatas\"])[\"metadatas\"]\n",
    "    \n",
    "    # Extract unique categories and sources\n",
    "    categories = set()\n",
    "    sources = set()\n",
    "    \n",
    "    for meta in all_metadata:\n",
    "        if \"category\" in meta and meta[\"category\"]:\n",
    "            categories.add(meta[\"category\"])\n",
    "        if \"source\" in meta and meta[\"source\"]:\n",
    "            sources.add(meta[\"source\"])\n",
    "    \n",
    "    print(\"Available categories:\")\n",
    "    for category in sorted(categories):\n",
    "        print(f\"- {category}\")\n",
    "        \n",
    "    print(\"\\nAvailable sources (sample):\")\n",
    "    for source in sorted(list(sources)[:5]):  # Show just a few sources\n",
    "        print(f\"- {source}\")\n",
    "    if len(sources) > 5:\n",
    "        print(f\"... and {len(sources) - 5} more sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered query: 'What are the core courses?' with filter: {'category': 'education'}\n",
      "Query: What are the core courses?\n",
      "--------------------------------------------------------------------------------\n",
      "Result #1 - ID: chunk_283\n",
      "Relevance: 0.3576\n",
      "Source: education_masters-programs_ms-in-applied-data-science_online-program.md\n",
      "Title: Online Program – DSI\n",
      "Category: education\n",
      "Content:\n",
      "### Core Courses (6)\n",
      "\n",
      "You will complete 6 core courses toward your [Master’s in Applied Data Science](https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/instructors-staff/) degree. Core courses allow you to build your theoretical data science knowledge and practic...\n",
      "--------------------------------------------------------------------------------\n",
      "Result #2 - ID: chunk_275\n",
      "Relevance: 0.1000\n",
      "Source: education_masters-programs_ms-in-applied-data-science_online-program.md\n",
      "Title: Online Program – DSI\n",
      "Category: education\n",
      "Content:\n",
      "Read More +\n",
      "Show Less -\n",
      "\n",
      "## Curriculum\n",
      "\n",
      "You will earn UChicago’s Master’s in Applied Data Science by successfully completing 12 courses (6 core, 4 elective, 2 Capstone) and our tailored Career Seminar\\*.\n",
      "\n",
      "Our rigorous curriculum is designed by and for data science innovators and leaders. Courses are...\n",
      "--------------------------------------------------------------------------------\n",
      "Result #3 - ID: chunk_296\n",
      "Relevance: 0.0809\n",
      "Source: education_masters-programs_ms-in-applied-data-science_online-program.md\n",
      "Title: Online Program – DSI\n",
      "Category: education\n",
      "Content:\n",
      "If you would like to gauge your preparation in these Foundational course topics, we recommend specific Coursera courses that cover very similar topics.\n",
      "\n",
      "    We have identified four Coursera courses which cover very similar topics. You can review the Coursera curricula to see if you are already well-...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "Filtered query: 'Who are the instructors?' with filter: {'category': 'education'}\n",
      "Query: Who are the instructors?\n",
      "--------------------------------------------------------------------------------\n",
      "Result #1 - ID: chunk_205\n",
      "Relevance: 0.0619\n",
      "Source: education_masters-programs_ms-in-applied-data-science_instructors-staff.md\n",
      "Title: Faculty, Instructors, Staff – DSI\n",
      "Category: education\n",
      "Content:\n",
      "course development and student experiences, including how online best practices can be leveraged by in-person courses. Briana is passionate about mentoring instructors in the creation of high-quality instructional resources, leveraging active learning strategies, and applying instructional technolog...\n",
      "--------------------------------------------------------------------------------\n",
      "Result #2 - ID: chunk_80\n",
      "Relevance: -0.0174\n",
      "Source: education_masters-programs_ms-in-applied-data-science_instructors-staff.md\n",
      "Title: Faculty, Instructors, Staff – DSI\n",
      "Category: education\n",
      "Content:\n",
      "### Faculty, Instructors\n",
      "\n",
      "* [\n",
      "\n",
      "  [Image: Image of Greg Green]\n",
      "\n",
      "  # Greg Green\n",
      "\n",
      "  Senior Instructional Professor; Senior Director of the DSI Polsky Transform Initiative; Senior Director of DSI Executive and Professional Education](https://datascience.uchicago.edu/people/greg-green/)\n",
      "* [\n",
      "\n",
      "  [Image: Im...\n",
      "--------------------------------------------------------------------------------\n",
      "Result #3 - ID: chunk_88\n",
      "Relevance: -0.0829\n",
      "Source: education_masters-programs_ms-in-applied-data-science_instructors-staff.md\n",
      "Title: Faculty, Instructors, Staff – DSI\n",
      "Category: education\n",
      "Content:\n",
      "# Mark Hendricks, PhD\n",
      "\n",
      "  Associate Senior Instructional Professor, FinMath](https://datascience.uchicago.edu/people/mark-hendricks-phd/)\n",
      "* [\n",
      "\n",
      "  [Image: Image of Sebastien Donadio, PhD]\n",
      "\n",
      "  # Sebastien Donadio, PhD\n",
      "\n",
      "  Instructor; Chief Technology Officer, TradAir](https://datascience.uchicago.edu/peop...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try some filtered queries\n",
    "filtered_queries = [\n",
    "    (\"What are the core courses?\", {\"category\": \"education\"}),\n",
    "    (\"Who are the instructors?\", {\"category\": \"education\"})\n",
    "]\n",
    "\n",
    "for query, filter_dict in filtered_queries:\n",
    "    print(f\"\\nFiltered query: '{query}' with filter: {filter_dict}\")\n",
    "    results = query_vector_database(\n",
    "        chroma_collection, \n",
    "        query, \n",
    "        embedding_model, \n",
    "        top_k=3, \n",
    "        filter_dict=filter_dict\n",
    "    )\n",
    "    display_query_results(results, query)\n",
    "    print(\"\\n\" + \"=\" * 100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Simple Retrieval Function\n",
    "\n",
    "Finally, let's create a simple retrieval function that can be used in a RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the core courses?\n",
      "\n",
      "Retrieved context:\n",
      "\n",
      "Context 1:\n",
      "--------------------------------------------------------------------------------\n",
      "### Core Courses (6)\n",
      "\n",
      "You will complete 6 core courses toward your [Master’s in Applied Data Science](https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/instructors-staff/) degree. Core courses allow you to build your theoretical data science knowledge and practice applying this theory to examine real-world business problems.\n",
      "\n",
      "### Elective Courses (4)\n",
      "[Source: education_masters-programs_ms-in-applied-data-science_online-program.md, Online Program – DSI]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Context 2:\n",
      "--------------------------------------------------------------------------------\n",
      "Read More +\n",
      "Show Less -\n",
      "\n",
      "## Curriculum\n",
      "\n",
      "You will earn UChicago’s Master’s in Applied Data Science by successfully completing 12 courses (6 core, 4 elective, 2 Capstone) and our tailored Career Seminar\\*.\n",
      "\n",
      "Our rigorous curriculum is designed by and for data science innovators and leaders. Courses are reviewed annually to ensure the content keeps pace with the [rapidly evolving landscape of data science](https://datascience.uchicago.edu/news-events/news/).\n",
      "[Source: education_masters-programs_ms-in-applied-data-science_online-program.md, Online Program – DSI]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Context 3:\n",
      "--------------------------------------------------------------------------------\n",
      "If you would like to gauge your preparation in these Foundational course topics, we recommend specific Coursera courses that cover very similar topics.\n",
      "\n",
      "    We have identified four Coursera courses which cover very similar topics. You can review the Coursera curricula to see if you are already well-prepared, or if you like, study their materials to brush up on some or all of these topics.\n",
      "[Source: education_masters-programs_ms-in-applied-data-science_online-program.md, Online Program – DSI]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def retrieve_context(query, top_k=5, filter_dict=None):\n",
    "    \"\"\"\n",
    "    Retrieve relevant context for a given query.\n",
    "    This function can be used as part of a RAG system.\n",
    "    \n",
    "    Args:\n",
    "        query (str): User query\n",
    "        top_k (int): Number of results to retrieve\n",
    "        filter_dict (dict): Optional metadata filters\n",
    "        \n",
    "    Returns:\n",
    "        list: List of context strings with source information\n",
    "    \"\"\"\n",
    "    # Query the vector database\n",
    "    results = query_vector_database(\n",
    "        chroma_collection,\n",
    "        query,\n",
    "        embedding_model,\n",
    "        top_k=top_k,\n",
    "        filter_dict=filter_dict\n",
    "    )\n",
    "    \n",
    "    if results is None or len(results[\"ids\"]) == 0:\n",
    "        return [\"No relevant information found.\"]\n",
    "    \n",
    "    # Format the retrieved context\n",
    "    context_list = []\n",
    "    for i in range(len(results[\"ids\"][0])):\n",
    "        document = results[\"documents\"][0][i]\n",
    "        metadata = results[\"metadatas\"][0][i]\n",
    "        \n",
    "        # Add source information\n",
    "        source = metadata.get(\"source\", \"Unknown source\")\n",
    "        title = metadata.get(\"title\", \"\")\n",
    "        source_info = f\"[Source: {source}\" + (f\", {title}\" if title else \"\") + \"]\"\n",
    "        \n",
    "        # Add the formatted context\n",
    "        context_list.append(f\"{document}\\n{source_info}\")\n",
    "    \n",
    "    return context_list\n",
    "\n",
    "# Example of how to use the retrieve_context function\n",
    "#query = \"What are the course requirements for the MS in Applied Data Science program?\"\n",
    "query = \"What are the core courses?\"\n",
    "retrieved_context = retrieve_context(query, top_k=3)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(\"\\nRetrieved context:\")\n",
    "for i, context in enumerate(retrieved_context):\n",
    "    print(f\"\\nContext {i+1}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(context)\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
