{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervisor-Worker Agentic Architecture for RAG Chatbot\n",
    "\n",
    "This notebook implements a Supervisor-Worker agentic architecture using the LangGraph framework to build a Retrieval-Augmented Generation (RAG) chatbot that answers queries about a university Master's program in Applied Data Science.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "The architecture consists of:\n",
    "\n",
    "1. **Supervisor Agent**: Manages workflow execution, routes queries, evaluates results, and makes decisions about re-retrieval or answer refinement.\n",
    "2. **Worker Agents**:\n",
    "   - **Router Agent**: Classifies incoming queries to identify the type of information needed\n",
    "   - **Retriever Agent**: Performs semantic similarity retrieval from ChromaDB\n",
    "   - **Grader/Verifier Agent**: Evaluates the quality and relevance of retrieved documents\n",
    "   - **Reasoner/Answer Generator**: Synthesizes answers from graded documents\n",
    "   - **Summarizer Agent** (optional): Generates concise summaries of lengthy content\n",
    "\n",
    "## Data Context\n",
    "\n",
    "The chatbot uses information stored in a ChromaDB vector database containing markdown files with:\n",
    "- Faculty and instructor bios\n",
    "- Detailed course descriptions\n",
    "- Tuition, fees, and financial aid details\n",
    "- General program information, events, and academic content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "from typing import List, Dict, Any, Literal, TypedDict, Optional, Annotated, Tuple, Union\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_agent_executor\n",
    "import langsmith\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, FunctionMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Vector database\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# For visualizing the graph (optional)\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the OpenAI API key for our agents and define the ChromaDB paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file (if you have one)\n",
    "load_dotenv()\n",
    "\n",
    "# Set your OpenAI API key here if not using .env file\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "# Path to ChromaDB\n",
    "CHROMA_DIR = \"../data/chroma_db\"\n",
    "COLLECTION_NAME = \"ms_applied_data_science\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChromaDB client and connect to existing collection\n",
    "def initialize_chroma_client():\n",
    "    \"\"\"Initialize the ChromaDB client and connect to the existing collection.\"\"\"\n",
    "    try:\n",
    "        client = chromadb.PersistentClient(path=CHROMA_DIR)\n",
    "        collection = client.get_collection(name=COLLECTION_NAME)\n",
    "        print(f\"Successfully connected to ChromaDB collection: {COLLECTION_NAME}\")\n",
    "        return client, collection\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to ChromaDB: {e}\")\n",
    "        print(\"Please make sure you've run the vector_database.ipynb notebook first.\")\n",
    "        return None, None\n",
    "\n",
    "# Initialize Sentence Transformer model for query embedding\n",
    "def initialize_embedding_model(model_name=\"all-MiniLM-L6-v2\"):\n",
    "    try:\n",
    "        model = SentenceTransformer(model_name)\n",
    "        print(f\"Loaded Sentence Transformer model: {model_name}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Initialize ChromaDB and embedding model\n",
    "chroma_client, chroma_collection = initialize_chroma_client()\n",
    "embedding_model = initialize_embedding_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
