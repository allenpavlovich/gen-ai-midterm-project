{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 📊 RAG System Evaluation\n",
        "\n",
        "**Purpose:**  \n",
        "Evaluate the end-to-end Retrieval-Augmented Generation (RAG) pipeline using Ragas metrics (Faithfulness, Answer Relevancy, Context Precision & Recall) on a fixed set of professor-supplied questions.\n",
        "\n",
        "**Contents:**\n",
        "1. Environment setup & imports  \n",
        "2. Instantiate production RAG generator (placeholder)  \n",
        "3. Load and configure vector retriever  \n",
        "4. Define evaluation questions & gold references  \n",
        "5. Build Ragas `SingleTurnSample`s  \n",
        "6. Configure and run Ragas evaluation  \n",
        "7. Display & save results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI8xI2n1prZE",
        "outputId": "439752b5-4cd3-4939-cca3-bf892815b17e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "# pip install ragas langchain-openai\n",
        "# !pip install -qU langchain-chroma langchain-core  # run once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, pathlib\n",
        "PROJECT_ROOT = pathlib.Path().resolve().parent      # parent of notebooks/\n",
        "SRC_DIR = PROJECT_ROOT / \"src\"\n",
        "sys.path.append(str(SRC_DIR))                       # now “src” is importable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amVdQpJbpu-D"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────────────\n",
        "# 0. Setup imports and paths\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "import sys, pathlib\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# If your notebook sits next to src/, add it to sys.path\n",
        "PROJECT_ROOT = pathlib.Path().resolve().parent\n",
        "sys.path.append(str(PROJECT_ROOT / \"src\"))\n",
        "\n",
        "load_dotenv()  # loads OPENAI_API_KEY or other credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "# 1. Imports for RAG evaluation\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "from ragas import SingleTurnSample, EvaluationDataset, evaluate\n",
        "from ragas.metrics import Faithfulness, AnswerRelevancy, ContextPrecision, ContextRecall\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from langchain_openai import ChatOpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ─────────────────────────────────────────────────────────────────────\n",
        "# 2. Instantiate your RAG generator model (placeholder)\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "# TODO: replace this with your actual RAGChatbot or RetrievalQA chain\n",
        "# e.g. from rag_chatbot import RAGChatbot\n",
        "# chatbot = RAGChatbot(model=\"gpt-3.5-turbo\")\n",
        "chatbot = None  # <-- placeholder for your RAG pipeline instance\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "# 3. Instantiate the judge LLM wrapper\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "# GPT-4 will act as the judge for faithfulness, relevancy, etc.\n",
        "judge_llm = LangchainLLMWrapper(\n",
        "    ChatOpenAI(\n",
        "        model=\"gpt-4\",\n",
        "        temperature=0\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "# 4. Define your evaluation questions + gold references\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "evaluation_data = [\n",
        "    {\n",
        "        \"question\": \"What is tuition cost for the program?\",\n",
        "        \"reference\": \"Tuition for the MS in Applied Data Science program: $5,967 per course/$71,604 total tuition\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What scholarships are available?\",\n",
        "        \"reference\": \"The Data Science Institute Scholarship, MS in Applied Data Science Alumni Scholarship\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What are the deadlines for the in-person program?\",\n",
        "        \"reference\": (\n",
        "            \"November 7, 2024 – Priority Application Deadline; \"\n",
        "            \"December 4, 2024 – Scholarship Priority Deadline; \"\n",
        "            \"January 21, 2025 – International Application Deadline; \"\n",
        "            \"March 4, 2025 – Second Priority Application Deadline; \"\n",
        "            \"May 6, 2025 – Third Priority Application Deadline; \"\n",
        "            \"June 23, 2025 – Final Application Deadline\"\n",
        "        )\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ─────────────────────────────────────────────────────────────────────\n",
        "# 5. Define rag_query function (placeholder)\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "def rag_query(question: str):\n",
        "    \"\"\"\n",
        "    Placeholder for your actual RAG pipeline call.\n",
        "    Should return:\n",
        "      - answer: str        ← model-generated answer\n",
        "      - contexts: list[str] ← list of retrieved chunk texts\n",
        "    \"\"\"\n",
        "    # TODO: replace the following two lines with your RAG pipeline call\n",
        "    answer = \"<YOUR_MODEL_GENERATED_ANSWER>\"  \n",
        "    contexts = [\"<CHUNK TEXT 1>\", \"<CHUNK TEXT 2>\", \"...\"]  \n",
        "    return answer, contexts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80937246f0c6452a9b7643a6a120e9ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[9]: OutputParserException(Invalid json output: {\n",
            "    \"question\": \"<YOUR_MODEL_GENERATED_QUESTION>\",\n",
            "    \"noncommittal\": <1_OR_0>\n",
            "}\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE )\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
            "Exception raised in Job[1]: RagasOutputParserException(The output parser failed to parse the output including retries.)\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
            "Exception raised in Job[5]: OutputParserException(Failed to parse StringIO from completion {}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE )\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt response_relevance_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
            "Exception raised in Job[3]: OutputParserException(Failed to parse StringIO from completion {}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE )\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────────────\n",
        "# 6. Build Ragas samples from evaluation_data\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "samples = []\n",
        "for item in evaluation_data:\n",
        "    q = item[\"question\"]\n",
        "    gt = item[\"reference\"]\n",
        "    \n",
        "    # call your rag_query (currently placeholder)\n",
        "    answer, retrieved_contexts = rag_query(q)\n",
        "    \n",
        "    samples.append(\n",
        "        SingleTurnSample(\n",
        "            user_input=q,\n",
        "            retrieved_contexts=retrieved_contexts,\n",
        "            response=answer,\n",
        "            reference=gt,\n",
        "        )\n",
        "    )\n",
        "\n",
        "dataset = EvaluationDataset(samples=samples)\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "# 7. Define metrics for evaluation\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "metrics = [\n",
        "    Faithfulness(),\n",
        "    AnswerRelevancy(),\n",
        "    ContextPrecision(),\n",
        "    ContextRecall(),\n",
        "]\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "# 8. Run Ragas evaluation\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "results = evaluate(\n",
        "    dataset=dataset,\n",
        "    metrics=metrics,\n",
        "    llm=judge_llm\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>retrieved_contexts</th>\n",
              "      <th>response</th>\n",
              "      <th>reference</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>context_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is tuition cost for the program?</td>\n",
              "      <td>[&lt;CHUNK TEXT 1&gt;, &lt;CHUNK TEXT 2&gt;, ...]</td>\n",
              "      <td>&lt;YOUR_MODEL_GENERATED_ANSWER&gt;</td>\n",
              "      <td>Tuition for the MS in Applied Data Science pro...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What scholarships are available?</td>\n",
              "      <td>[&lt;CHUNK TEXT 1&gt;, &lt;CHUNK TEXT 2&gt;, ...]</td>\n",
              "      <td>&lt;YOUR_MODEL_GENERATED_ANSWER&gt;</td>\n",
              "      <td>The Data Science Institute Scholarship, MS in ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What are the deadlines for the in-person program?</td>\n",
              "      <td>[&lt;CHUNK TEXT 1&gt;, &lt;CHUNK TEXT 2&gt;, ...]</td>\n",
              "      <td>&lt;YOUR_MODEL_GENERATED_ANSWER&gt;</td>\n",
              "      <td>November 7, 2024 – Priority Application Deadli...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          user_input  \\\n",
              "0              What is tuition cost for the program?   \n",
              "1                   What scholarships are available?   \n",
              "2  What are the deadlines for the in-person program?   \n",
              "\n",
              "                      retrieved_contexts                       response  \\\n",
              "0  [<CHUNK TEXT 1>, <CHUNK TEXT 2>, ...]  <YOUR_MODEL_GENERATED_ANSWER>   \n",
              "1  [<CHUNK TEXT 1>, <CHUNK TEXT 2>, ...]  <YOUR_MODEL_GENERATED_ANSWER>   \n",
              "2  [<CHUNK TEXT 1>, <CHUNK TEXT 2>, ...]  <YOUR_MODEL_GENERATED_ANSWER>   \n",
              "\n",
              "                                           reference  faithfulness  \\\n",
              "0  Tuition for the MS in Applied Data Science pro...           0.0   \n",
              "1  The Data Science Institute Scholarship, MS in ...           0.0   \n",
              "2  November 7, 2024 – Priority Application Deadli...           0.0   \n",
              "\n",
              "   answer_relevancy  context_precision  context_recall  \n",
              "0               NaN                0.0             NaN  \n",
              "1               NaN                0.0             0.0  \n",
              "2               NaN                0.0             0.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────────────\n",
        "# 9. Convert to DataFrame, display, and save\n",
        "# ─────────────────────────────────────────────────────────────────────\n",
        "df = results.to_pandas()\n",
        "display(df)\n",
        "df.to_csv(\"rag_eval_results.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "# Adjust this to the real directory you used when building the index:\n",
        "CHROMA_DIR = pathlib.Path(\"../data/chroma_index\").expanduser().resolve()\n",
        "print(\"Looking for Chroma files in:\", CHROMA_DIR)\n",
        "print(\"Exists?\", CHROMA_DIR.exists(), \"| Contents:\", list(CHROMA_DIR.iterdir())[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collections in this directory: [Collection(name=uchicago_ms_applied_ds_header_chunks), Collection(name=langchain)]\n"
          ]
        }
      ],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "import pathlib\n",
        "\n",
        "# Open the same directory\n",
        "CHROMA_DIR = pathlib.Path(\"../data/chroma_index\").resolve()\n",
        "emb = OpenAIEmbeddings()\n",
        "\n",
        "# Don’t specify a collection_name; let Chroma client tell us what’s inside\n",
        "vectordb_client = Chroma(\n",
        "    persist_directory=str(CHROMA_DIR),\n",
        "    embedding_function=emb,\n",
        ")\n",
        "\n",
        "# Inspect its internal client\n",
        "collections = vectordb_client._client.list_collections()\n",
        "print(\"Collections in this directory:\", collections)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# V1 Code from here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas import SingleTurnSample, EvaluationDataset\n",
        "\n",
        "samples = [\n",
        "    SingleTurnSample(\n",
        "        user_input=\"What is tuition cost for the program?\",\n",
        "        retrieved_contexts=[\n",
        "            \"Tuition for the MS in Applied Data Science program: $5,967 per course/$71,604 total tuition\"\n",
        "        ],\n",
        "        response=\"The total tuition for the MS in Applied Data Science program is $71,604.\",\n",
        "        reference=\"Tuition for the MS in Applied Data Science program: $5,967 per course/$71,604 total tuition\"\n",
        "    ),\n",
        "    SingleTurnSample(\n",
        "        user_input=\"What scholarships are available?\",\n",
        "        retrieved_contexts=[\n",
        "            \"The Data Science Institute Scholarship, MS in Applied Data Science Alumni Scholarship\"\n",
        "        ],\n",
        "        response=\"Available scholarships include the Data Science Institute Scholarship and the Alumni Scholarship.\",\n",
        "        reference=\"The Data Science Institute Scholarship, MS in Applied Data Science Alumni Scholarship\"\n",
        "    ),\n",
        "    SingleTurnSample(\n",
        "        user_input=\"What are the deadlines for the in-person program?\",\n",
        "        retrieved_contexts=[\n",
        "            \"November 7, 2024 – Priority Application Deadline\\nDecember 4, 2024 – Scholarship Priority Deadline\\nJanuary 21, 2025 – International Deadline...\"\n",
        "        ],\n",
        "        response=\"The deadlines include November 7, December 4, January 21, March 4, May 6, and June 23.\",\n",
        "        reference=\"November 7, 2024 – Priority Application Deadline\\nDecember 4, 2024 – Scholarship Priority Deadline...\"\n",
        "    ),\n",
        "]\n",
        "evaluation_dataset = EvaluationDataset(samples=samples)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.metrics import Faithfulness, AnswerRelevancy, ContextPrecision, ContextRecall\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4\"))\n",
        "\n",
        "metrics = [\n",
        "    Faithfulness(llm=evaluator_llm),\n",
        "    AnswerRelevancy(llm=evaluator_llm),\n",
        "    ContextPrecision(llm=evaluator_llm),\n",
        "    ContextRecall(llm=evaluator_llm)\n",
        "]\n",
        "\n",
        "evaluate(dataset=evaluation_dataset, metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epo4RBMWp9ha"
      },
      "outputs": [],
      "source": [
        "from ragas.metrics import Faithfulness, AnswerRelevancy, ContextPrecision, ContextRecall\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()  # Loads variables from .env\n",
        "\n",
        "# Optional: Check that the key is loaded\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "5827130903ba42ff869f0d9b6d2e8e42",
            "415e2fa91c7e4c47a55eba5e4c9c28cd",
            "13d0146943c148ab9b6894062682e368",
            "f26fd5ee686043a7ba34682c04d13271",
            "0bd6c61086604e3d98a65409bb66eeb6",
            "01fbb903e99c428792c70d3daf312796",
            "d3904f83b68a47bc9d300bdf8b39d566",
            "d924bf38e5ab45988aa0db4dc242b7ec",
            "38fa6d4bf768421e9cd5829dc19a8fb4",
            "398409e675b944fabaeb1ad6ac2a0a80",
            "beca2d02eb8241fbba691c4e80eff5ca"
          ]
        },
        "id": "UZN8x9lHqsrP",
        "outputId": "d21bec4c-ce87-40c3-aa42-e1f739c21d94"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa11f9f7a38e40eba95b392df10a25e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas import evaluate\n",
        "\n",
        "metrics = [\n",
        "    Faithfulness(llm=evaluator_llm),\n",
        "    AnswerRelevancy(llm=evaluator_llm),\n",
        "    ContextPrecision(llm=evaluator_llm),\n",
        "    ContextRecall(llm=evaluator_llm)\n",
        "]\n",
        "\n",
        "results = evaluate(dataset=evaluation_dataset, metrics=metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc84wYUcrBV4",
        "outputId": "7c5cc5b1-57ea-4c2a-e445-22465f4479b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                          user_input  \\\n",
            "0              What is tuition cost for the program?   \n",
            "1                   What scholarships are available?   \n",
            "2  What are the deadlines for the in-person program?   \n",
            "\n",
            "                                  retrieved_contexts  \\\n",
            "0  [Tuition for the MS in Applied Data Science pr...   \n",
            "1  [The Data Science Institute Scholarship, MS in...   \n",
            "2  [November 7, 2024 – Priority Application Deadl...   \n",
            "\n",
            "                                            response  \\\n",
            "0  The total tuition for the MS in Applied Data S...   \n",
            "1  Available scholarships include the Data Scienc...   \n",
            "2  The deadlines include November 7, December 4, ...   \n",
            "\n",
            "                                           reference  faithfulness  \\\n",
            "0  Tuition for the MS in Applied Data Science pro...           1.0   \n",
            "1  The Data Science Institute Scholarship, MS in ...           0.0   \n",
            "2  November 7, 2024 – Priority Application Deadli...           0.5   \n",
            "\n",
            "   answer_relevancy  context_precision  context_recall  \n",
            "0          0.894362                1.0             1.0  \n",
            "1          1.000000                1.0             1.0  \n",
            "2          0.906658                1.0             1.0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_results = results.to_pandas()\n",
        "print(df_results)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01fbb903e99c428792c70d3daf312796": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd6c61086604e3d98a65409bb66eeb6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13d0146943c148ab9b6894062682e368": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d924bf38e5ab45988aa0db4dc242b7ec",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38fa6d4bf768421e9cd5829dc19a8fb4",
            "value": 12
          }
        },
        "38fa6d4bf768421e9cd5829dc19a8fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "398409e675b944fabaeb1ad6ac2a0a80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "415e2fa91c7e4c47a55eba5e4c9c28cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01fbb903e99c428792c70d3daf312796",
            "placeholder": "​",
            "style": "IPY_MODEL_d3904f83b68a47bc9d300bdf8b39d566",
            "value": "Evaluating: 100%"
          }
        },
        "5827130903ba42ff869f0d9b6d2e8e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_415e2fa91c7e4c47a55eba5e4c9c28cd",
              "IPY_MODEL_13d0146943c148ab9b6894062682e368",
              "IPY_MODEL_f26fd5ee686043a7ba34682c04d13271"
            ],
            "layout": "IPY_MODEL_0bd6c61086604e3d98a65409bb66eeb6"
          }
        },
        "beca2d02eb8241fbba691c4e80eff5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3904f83b68a47bc9d300bdf8b39d566": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d924bf38e5ab45988aa0db4dc242b7ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f26fd5ee686043a7ba34682c04d13271": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_398409e675b944fabaeb1ad6ac2a0a80",
            "placeholder": "​",
            "style": "IPY_MODEL_beca2d02eb8241fbba691c4e80eff5ca",
            "value": " 12/12 [00:56&lt;00:00,  7.47s/it]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
