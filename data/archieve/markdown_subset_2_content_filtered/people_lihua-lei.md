---
title: Lihua Lei – DSI
original_url: https://datascience.uchicago.edu/people/lihua-lei
category: people
date: 2025-05-04
---

<!-- Table-like structure detected -->

!

## Share

* Email page on Facebook (opens new window)
* Share page on X (opens new window)
* Email Page (opens new window)

<!-- Table-like structure detected -->

People

# Lihua Lei

Currently: Assistant Professor, Stanford University; Previously: Postdoctoral Scholar, Stanford University

**Bio:**Lihua Lei is a postdoctoral scholar in Statistics at Stanford University, advised by Emmanuel Candès. His current research focuses on developing rigorous statistical methodologies for uncertainty quantification in applications involving complicated decision-making processes, to enhance reliability, robustness and fairness of the system. Prior to joining Stanford, he obtained his Ph.D. in statistics at UC Berkeley, advised by Peter Bickel and Michael Jordan. His research areas include causal inference, multiple hypothesis testing, network clustering, and stochastic optimization.

**Talk Title:**Distribution-Free Assessment of Population Overlap in Observational Studies

**Talk Abstract:**Overlap in baseline covariates between treated and control groups, also known as positivity or common support, is one of the most fundamental assumptions in observational causal inference. Assessing this assumption is often ad hoc, however, and can give misleading results. For example, the common practice of examining the empirical distribution of estimated propensity scores is heavily dependent on model specification and has poor uncertainty quantification. In this paper, we propose a formal statistical framework for assessing the extrema of the population propensity score; e.g., the propensity score lies in [0.1, 0.9] almost surely. We develop a family of upper confidence bounds, which we term O-values, for this quantity. We show these bounds are valid in finite samples so long as the observations are independent and identically distributed, without requiring any further modeling assumptions on the data generating process. We also use extensive simulations to show that these bounds are reasonably tight in practice. Finally, we demonstrate this approach using several benchmark observational studies, showing how to build our proposed method into the observational causal inference workflow.