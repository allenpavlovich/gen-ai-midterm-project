---
title: Zhijing Jin – DSI
original_url: https://datascience.uchicago.edu/people/zhijing-jin
category: people
date: 2025-05-04
---

<!-- Table-like structure detected -->

!

## Share

* Email page on Facebook (opens new window)
* Share page on X (opens new window)
* Email Page (opens new window)

<!-- Table-like structure detected -->

People / Non-DSI

# Zhijing Jin

PhD Candidate, Max Planck Institute & ETH Zürich

**Bio:**Zhijing Jin (she/her) is a Ph.D. at Max Planck Institute & ETH. Her research focuses on socially responsible NLP via causal and moral principles. Specifically, she works on expanding the impact of NLP by promoting NLP for social good, and developing CausalNLP to improve robustness, fairness, and interpretability of NLP models, as well as analyze the causes of social problems. She has published at many NLP and AI venues (e.g., ACL, EMNLP, NAACL, NeurIPS, AAAI, AISTATS). Her work has been featured in MIT News, ACM TechNews, and Synced. She is actively involved in AI for social good, as the organizer of NLP for Positive Impact Workshops at ACL 2021, EMNLP 2022, and EMNLP 2024, Moral AI Workshop at NeurIPS 2023, and RobustML Workshop at ICLR 2021. To support the NLP research community, she organizes the ACL Year-Round Mentorship Program. To foster the causality research community, she organized the Tutorial on CausalNLP at EMNLP 2022, and served as the Publications Chair for the 1st conference on Causal Learning and Reasoning (CLeaR).

**Talk Title:** Socially responsible NLP via causal and moral principles

**Abstract:**We are currently navigating through an era marked by numerous social challenges: the COVID pandemic, climate change, as well as escalating concerns on the safety of large language models (LLMs). With all these concerning challenges, I establish my research on socially responsible NLP using causal and moral principles. Specifically, I use causal inference to benchmark existing LLMs’ reasoning ability, analyze the failure modes of LLMs, and interpret the relation between data collection and model learning. Further, I combine interdisciplinary knowledge from moral philosophy to design socially-important moral questions to test LLMs, and propose standards for future models to be more morally safe. In this talk, I will introduce my research on these lines, and put forward an outlook for socially responsible NLP.

Contact Info

Website

<https://zhijing-jin.com>