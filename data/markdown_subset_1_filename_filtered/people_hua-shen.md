---
title: Hua Shen â€“ DSI
original_url: https://datascience.uchicago.edu/people/hua-shen
category: people
date: 2025-05-04
---

<!-- Table-like structure detected -->

!

## Share

* Email page on Facebook (opens new window)
* Share page on X (opens new window)
* Email Page (opens new window)

<!-- Table-like structure detected -->

People / Non-DSI

# Hua Shen

Postdoctoral Research Fellow, University of Michigan

**Bio:**Hua Shen is a postdoc research fellow at University of Michigan, advised by Dr. David Jurgens, working on facilitating human-centered AI explanation and interaction in the fields of NLP and HCI. She obtained her PhD at Penn State during 2019-2023, supervised by Kenneth Huang, and closely worked with Sherry Wu from CMU. Her research focused on helping humans explain and communicate with AI models (e.g., LLM) via interactions or conversations and, moreover, enhancing AI models by aligning their behavior with human feedback. Her work has been recognized as the Best Paper Honorable Mentioned Award at IUI 2023. She was invited to talk about her research at CMU, Princeton, Google, Amazon, etc. The research finding was also covered by media like PSU News, TechXplore News, etc. Besides, she conducted research on Speech Processing in her Google AI and Amazon AI internships.

**Talk Title:**Towards Useful AI Interpretability for Humans via Interactive AI Explanations

**Abstract:** Although the plethora of eXplainable AI (XAI) approaches are validated to reflect the model behavior faithfully, how humans can understand and further use AI explanations still needs to be explored. Therefore, we conducted two human studies to investigate how much AI explanations can be useful for end users in Computer Vision and NLP fields, including asking humans to analyze model failures in image classification tasks and simulate model predictions in text classification tasks, respectively. Our results showed that explanations are not always helpful for human understanding in practical tasks of both fields. To gain insights into possible reasons, we examined the gaps between the status quo of XAI techniques and real-world user demands, by surveying 200+ XAI papers and comparing them with the practical user needs. As a result, we found that humans need diverse XAI types to interpret the whole AI system lifecycle. However, there is a lack of one-size-fits-all XAI techniques to cater to the diverse and dynamic human needs in practice. Hence, we propose a Conversational XAI prototype, ConvXAI, as a universal XAI dialogue interface that empowers users to request various XAI questions across AI lifecycle and receive explanations with diverse formats. We applied ConvXAI to improve human performance in the human-AI co-writing tasks. The findings from two studies with 21 users show that ConvXAI is useful for humans in understanding AI feedback and improving writing productivity and quality. Overall, the studies contribute insights into the design space of facilitating useful XAI techniques for humans in practice.

Contact Info

Website

<https://hua-shen.org/>